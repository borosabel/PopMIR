{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T12:59:40.330863Z",
     "start_time": "2024-06-11T12:59:40.326951Z"
    }
   },
   "id": "90fd4bc6ba1d44e4",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T12:59:40.732443Z",
     "start_time": "2024-06-11T12:59:40.730792Z"
    }
   },
   "id": "928095a3da1d6a56",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T12:59:42.171025Z",
     "start_time": "2024-06-11T12:59:40.929451Z"
    }
   },
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # or RandomForestRegressor for regression tasks\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "importlib.reload(utils)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def compute_features(row):\n",
    "    audio_path = row['Path']\n",
    "    features_dict = {}\n",
    "\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(audio_path)\n",
    "\n",
    "        # MEL SPECTROGRAM FEATURES\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "        mel_mean = np.mean(S_dB, axis=1)\n",
    "        mel_std = np.std(S_dB, axis=1)\n",
    "\n",
    "        for i, (mean, std) in enumerate(zip(mel_mean, mel_std)):\n",
    "            features_dict[f'Raw_Melspect_Mean_{i}'] = mean\n",
    "            features_dict[f'Raw_Melspect_Std_{i}'] = std\n",
    "\n",
    "        # MFCC FEATURES\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "        mfcc_means = np.mean(mfccs, axis=1)\n",
    "        mfcc_stds = np.std(mfccs, axis=1)\n",
    "        delta_mfccs_means = np.mean(delta_mfccs, axis=1)\n",
    "        delta2_mfccs_means = np.mean(delta2_mfccs, axis=1)\n",
    "        delta_mfccs_stds = np.std(delta_mfccs, axis=1)\n",
    "        delta2_mfccs_stds = np.std(delta2_mfccs, axis=1)\n",
    "\n",
    "        for i, (mean, std, delta_mean, delta_std, delta2_mean, delta2_std) in enumerate(zip(\n",
    "                mfcc_means, mfcc_stds, delta_mfccs_means, delta_mfccs_stds, delta2_mfccs_means, delta2_mfccs_stds)):\n",
    "            features_dict[f'Raw_MFCC_Mean_{i}'] = mean\n",
    "            features_dict[f'Raw_MFCC_Std_{i}'] = std\n",
    "            features_dict[f'Delta_MFCC_Mean_{i}'] = delta_mean\n",
    "            features_dict[f'Delta_MFCC_Std_{i}'] = delta_std\n",
    "            features_dict[f'Delta2_MFCC_Mean_{i}'] = delta2_mean\n",
    "            features_dict[f'Delta2_MFCC_Std_{i}'] = delta2_std\n",
    "\n",
    "        # Additional Features\n",
    "        # Utilize utility functions to calculate additional features\n",
    "        features_dict.update({\n",
    "            'brightness': utils.calculate_brightness(y, sr),\n",
    "            'band_energy': utils.band_energy(y, sr),\n",
    "            'envelope_flatness': utils.envelope_flatness(y),\n",
    "            'envelope_kurtosis': utils.envelope_kurtosis(y),\n",
    "            'envelope_quantile_range': utils.calculate_envelope_quantile_range(y),\n",
    "            'harmonic_energy': utils.calculate_harmonic_energy(y),\n",
    "            'harmonic_percussive_ratio': utils.calculate_harmonic_percussive_ratio(y),\n",
    "            'high_frequency_ratio': utils.calculate_high_frequency_ratio(y, sr),\n",
    "            'loudness_sone': utils.calculate_loudness_sone(audio_path),\n",
    "            'low_energy': utils.calculate_low_energy(y),\n",
    "            'max_rms_position': utils.find_max_rms_position(y, sr),\n",
    "            'max_rms_value': utils.find_max_rms_value(y),\n",
    "            'segments_based_on_rms': utils.count_segments_based_on_rms(y),\n",
    "            'percussive_energy': utils.calculate_percussive_energy(y),\n",
    "            'mean_rms_energy': utils.calculate_average_rms_energy(y),\n",
    "            'mean_average_spectral_centroid': utils.calculate_average_spectral_centroid(y, sr),\n",
    "            'spectral_entropy': utils.calculate_spectral_entropy(y),\n",
    "            'spectral_flatness': utils.average_calculate_spectral_flatness(y),\n",
    "            'zero_crossing_rate': utils.zero_crossing_rate(y)  # This needs to be defined similarly in your utils\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process: {audio_path}\")\n",
    "        print(e)\n",
    "        # features_dict['error'] = str(e)  # You might want to return an error indicator\n",
    "\n",
    "    return pd.Series(features_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T08:58:00.195316Z",
     "start_time": "2024-05-09T08:58:00.193955Z"
    }
   },
   "id": "9ccb4526656d6171",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tqdm.pandas(desc=\"Computing features\")\n",
    "result = df.progress_apply(compute_features, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T01:10:52.711673Z",
     "start_time": "2024-05-09T08:58:00.196681Z"
    }
   },
   "id": "c602dfb250470ce",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Here I am just loading the saved progress because calculating everything would take like 2 days but above you can see the utility functions I used to calculate the features.\n",
    "df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data.xlsx', engine='openpyxl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T13:00:07.994964Z",
     "start_time": "2024-06-11T13:00:07.827621Z"
    }
   },
   "id": "90a72ac400089db0",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:00:11.905753Z",
     "start_time": "2024-06-11T13:00:11.902491Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "5f2c8cd810a77e68",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Here I am just loading the saved progress because calculating everything would take like 2 days but above you can see the utility functions I used to calculate the features.\n",
    "features = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/hardness_features.xlsx', engine='openpyxl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T13:00:45.588967Z",
     "start_time": "2024-06-11T13:00:42.275026Z"
    }
   },
   "id": "b904127cb8ccf729",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:00:47.757477Z",
     "start_time": "2024-06-11T13:00:47.752584Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "531fd035b7e898ba",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "le = LabelEncoder()\n",
    "labels = pd.DataFrame(le.fit_transform(df['Coast']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T09:24:39.933816Z",
     "start_time": "2024-05-10T09:24:39.925871Z"
    }
   },
   "id": "e5609f42fd1fcf57",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "features.drop('Unnamed: 0', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T10:31:32.062543Z",
     "start_time": "2024-05-10T10:31:32.037835Z"
    }
   },
   "id": "df0383d581e5e909",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "features['Tempo'] = df['Tempo1']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T10:47:24.265173Z",
     "start_time": "2024-05-10T10:47:24.254268Z"
    }
   },
   "id": "6216ebd3dda4ba50",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "features.to_excel('hardness_features.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:59:23.825841Z",
     "start_time": "2024-05-10T11:59:17.073425Z"
    }
   },
   "id": "5707d01a82574b59",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "k = 10\n",
    "# I use StratifiedKFold to keep the balance of the dataset consistent.\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T10:47:35.882410Z",
     "start_time": "2024-05-10T10:47:35.870495Z"
    }
   },
   "id": "25d2e36ee0593b1e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize your model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# List to store each fold's F1 score\n",
    "f1_scores = []\n",
    "\n",
    "# Initialize an empty array to hold the sum of all confusion matrices\n",
    "cumulative_conf_matrix = np.zeros((2, 2))  # Adjust the size if not binary classification\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=0)\n",
    "\n",
    "# Assuming 'features' and 'labels' are defined, and 'skf' is your StratifiedKFold instance\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)  # Example definition\n",
    "\n",
    "# Split your data and use tqdm for the progress bar\n",
    "for train_index, test_index in tqdm(skf.split(features, labels), total=skf.get_n_splits(), desc=\"Folds\"):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "    y_train = np.ravel(y_train)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict using the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute the confusion matrix and add it to the cumulative matrix\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    cumulative_conf_matrix += conf_mat\n",
    "\n",
    "    # Calculate F1 score and append to list\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')  # Change 'macro' as needed for your classification scheme\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Print the cumulative confusion matrix\n",
    "print(\"Cumulative Confusion Matrix:\")\n",
    "print(cumulative_conf_matrix)\n",
    "\n",
    "# Print average F1 score\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cumulative_conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Aggregated Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:02:05.400186Z",
     "start_time": "2024-05-10T10:47:37.267808Z"
    }
   },
   "id": "727e4198d4a54fb5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "best_model = RandomForestClassifier(random_state=42, **grid_search.best_params_)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "all_y_pred = []\n",
    "all_y_test = []\n",
    "\n",
    "for train_index, test_index in tqdm(skf.split(features, labels), total=skf.get_n_splits(), desc=\"Folds\"):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "    y_train = np.ravel(y_train)\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_test = np.ravel(y_test.to_numpy())\n",
    "    all_y_pred.extend(y_pred)\n",
    "    all_y_test.extend(y_test)\n",
    "\n",
    "print(\"Length of all_y_test:\", len(all_y_test))\n",
    "print(\"Length of all_y_pred:\", len(all_y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_y_test, all_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:02:25.469081Z",
     "start_time": "2024-05-10T11:02:22.223610Z"
    }
   },
   "id": "40a2555da271c1df",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "importances = best_model.feature_importances_\n",
    "feature_names = features.columns\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "# Optionally, convert to a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:02:30.757111Z",
     "start_time": "2024-05-10T11:02:30.743098Z"
    }
   },
   "id": "33d7aca6d25ccccb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "importance_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:02:49.246775Z",
     "start_time": "2024-05-10T11:02:49.227442Z"
    }
   },
   "id": "5066b062d12dd448",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ff660e0252a3194",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
