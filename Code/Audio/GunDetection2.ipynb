{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:55.068112Z",
     "start_time": "2024-09-02T14:12:54.916454Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:57.953648Z",
     "start_time": "2024-09-02T14:12:55.225510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "7c8aee8a9c9e9e0b",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:58.853400Z",
     "start_time": "2024-09-02T14:12:57.958265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Function to plot waveform\n",
    "def plot_waveform(audio, title, overlay_position=None):\n",
    "    samples = np.array(audio.get_array_of_samples())\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(samples)\n",
    "    if overlay_position is not None:\n",
    "        plt.axvline(x=overlay_position * audio.frame_rate // 1000, color='r', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot spectrogram\n",
    "def plot_spectrogram(audio, title, overlay_position=None):\n",
    "    samples = np.array(audio.get_array_of_samples())\n",
    "    f, t, Sxx = spectrogram(samples, fs=audio.frame_rate)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx))\n",
    "    if overlay_position is not None:\n",
    "        plt.axvline(x=overlay_position / 1000, color='r', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.colorbar(label='dB')\n",
    "    plt.show()\n",
    "\n",
    "# Function to convert pydub AudioSegment to numpy array for playback\n",
    "def audio_segment_to_np(audio_segment):\n",
    "    samples = np.array(audio_segment.get_array_of_samples())\n",
    "    # Normalize to the range [-1, 1]\n",
    "    return samples.astype(np.float32) / np.iinfo(samples.dtype).max\n",
    "\n",
    "# Load music and gunshot audio files\n",
    "music = AudioSegment.from_file(\"/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/west_coast/Ice-T/Retrun of The Real/Dear Homie.mp3\")\n",
    "gunshot = AudioSegment.from_file(\"/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/archive/M249/6 (8).wav\")\n",
    "\n",
    "music = music[:10000]\n",
    "\n",
    "music.export('./temp.mp3')"
   ],
   "id": "c88750f79b8b76df",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:28.375774Z",
     "start_time": "2024-08-30T14:45:28.196720Z"
    }
   },
   "cell_type": "code",
   "source": "w, s = torchaudio.load('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/west_coast/Ice-T/Retrun of The Real/Dear Homie.mp3')",
   "id": "5063a382c39add37",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:28.979316Z",
     "start_time": "2024-08-30T14:45:28.964640Z"
    }
   },
   "cell_type": "code",
   "source": "w_, s_ = torchaudio.load('./temp.mp3')",
   "id": "f97a1db7f6c652bd",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:29.547331Z",
     "start_time": "2024-08-30T14:45:29.484438Z"
    }
   },
   "cell_type": "code",
   "source": "ipd.Audio('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/west_coast/Ice-T/Retrun of The Real/Dear Homie.mp3')",
   "id": "c07b82ba87935a28",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:30.492460Z",
     "start_time": "2024-08-30T14:45:30.488476Z"
    }
   },
   "cell_type": "code",
   "source": "ipd.Audio('./temp.mp3')",
   "id": "b1f27e51242c0985",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Play original music and gunshot\n",
    "play(music)"
   ],
   "id": "6c194faecf939cd8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:49.964591Z",
     "start_time": "2024-08-30T14:45:47.672051Z"
    }
   },
   "cell_type": "code",
   "source": "play(gunshot)",
   "id": "8f78b518cd77d1c",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:51.941688Z",
     "start_time": "2024-08-30T14:45:51.936978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "position = 500  # position in milliseconds\n",
    "combined_audio = music.overlay(gunshot, position=position)"
   ],
   "id": "85407c0b76c35ef6",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:45:54.866260Z",
     "start_time": "2024-08-30T14:45:53.601542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_waveform(music, \"Original Music Waveform\")\n",
    "plot_waveform(combined_audio, \"Combined Audio Waveform\", overlay_position=position)\n",
    "plot_spectrogram(music, \"Original Music Spectrogram\")\n",
    "plot_spectrogram(combined_audio, \"Combined Audio Spectrogram\", overlay_position=position)"
   ],
   "id": "a69ab5d82476370f",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T13:26:49.996151Z",
     "start_time": "2024-09-02T13:26:49.364886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "with_gunshot_0 = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/Combined/with_gunshot_0.mp3'\n",
    "SAMPLING_RATE = 44100\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "audio = AudioSegment.from_file(with_gunshot_0)\n",
    "\n",
    "# Function to play a frame excerpt\n",
    "def play_excerpt(audio, num_frames, start_time_sec, sampling_rate, hop_length):\n",
    "    # Calculate the duration of the excerpt in seconds\n",
    "    excerpt_duration_sec = (num_frames - 1) * hop_length / sampling_rate\n",
    "    print(f\"Playing an excerpt of {excerpt_duration_sec:.2f} seconds ({num_frames} frames) starting at {start_time_sec} seconds\")\n",
    "\n",
    "    # Convert start time and duration to milliseconds for slicing the audio\n",
    "    start_time_ms = start_time_sec * 1000\n",
    "    excerpt_duration_ms = excerpt_duration_sec * 1000\n",
    "\n",
    "    # Extract the excerpt from the specified start time\n",
    "    excerpt = audio[start_time_ms:start_time_ms + excerpt_duration_ms]  # Take the segment starting at `start_time_ms`\n",
    "\n",
    "    play(excerpt)\n",
    "\n",
    "# Play a 15-frame long excerpt\n",
    "play_excerpt(audio, num_frames=15, start_time_sec=2, sampling_rate=SAMPLING_RATE, hop_length=HOP_LENGTH)"
   ],
   "id": "39eede3b1728803a",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T13:27:00.270526Z",
     "start_time": "2024-09-02T13:26:59.005476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Play an 86-frame long excerpt\n",
    "play_excerpt(audio, num_frames=86, start_time_sec=1.9, sampling_rate=SAMPLING_RATE, hop_length=HOP_LENGTH)"
   ],
   "id": "bbde41119e2a8227",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:46:07.816701Z",
     "start_time": "2024-08-30T14:46:01.854511Z"
    }
   },
   "cell_type": "code",
   "source": "play(combined_audio)",
   "id": "f60622791f7c9178",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:05.701949Z",
     "start_time": "2024-09-01T17:40:05.686975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.fc1 = nn.Linear(20 * 7 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 7 * 8)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = GunshotDetectionCNN()"
   ],
   "id": "f15e52c586a05fc1",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:06.332437Z",
     "start_time": "2024-09-01T17:40:06.328243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y in zip(spectograms, sample_rates, targets):\n",
    "            X_frames, y_frames = utils.make_frames(X, y)\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        tmp = th.cat(self.X)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "id": "66458c09f71a8b06",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:07.237991Z",
     "start_time": "2024-09-01T17:40:07.212393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/Combined'\n",
    "\n",
    "def generate_file_dataframe(folder_path):\n",
    "    # Initialize a list to store the records\n",
    "    records = []\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.mp3'):  # Only consider mp3 files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Determine values for the third and fourth columns based on the filename\n",
    "            if 'with_gunshot' in filename:\n",
    "                gunshot_flag = 1\n",
    "                label = 1\n",
    "                timestampt = [2.0]\n",
    "            elif 'without_gunshot' in filename:\n",
    "                gunshot_flag = 0\n",
    "                label = 0\n",
    "                timestampt = []\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Append the record to the list\n",
    "            records.append([file_path, timestampt, gunshot_flag, label])\n",
    "\n",
    "    # Create a DataFrame from the records\n",
    "    df = pd.DataFrame(records, columns=['filename', 'gunshot_location_in_seconds', 'num_gunshots', 'label'])\n",
    "    return df\n",
    "\n",
    "df = generate_file_dataframe(training_data_path)"
   ],
   "id": "44a70735036878e3",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:08.119771Z",
     "start_time": "2024-09-01T17:40:08.115808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = df[['filename', 'num_gunshots', 'gunshot_location_in_seconds']]\n",
    "labels = df[['label']]"
   ],
   "id": "89f391d338fb3cca",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:08.645759Z",
     "start_time": "2024-09-01T17:40:08.640974Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths, X_test_paths, y_train_paths, y_test_paths = train_test_split(files, labels, test_size=0.3, random_state=42)",
   "id": "ccaeec70f329f05e",
   "execution_count": 92,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:40:09.182454Z",
     "start_time": "2024-09-01T17:40:09.174220Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths",
   "id": "91126f1ba91cab5d",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:42:51.374307Z",
     "start_time": "2024-09-01T17:40:53.123688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms_train, sample_rates_train, labels_train = utils.preprocess_audio_train(X_train_paths, max_non_gunshot_samples=10)\n",
    "spectrograms_test, sample_rates_test, labels_test = utils.preprocess_audio_train(X_test_paths, max_non_gunshot_samples=10)"
   ],
   "id": "a65ea32ef87a40fe",
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:43:13.474400Z",
     "start_time": "2024-09-01T17:43:13.447798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 dimensions of mel-spectograms with 80 mel bands and 15 frames.\n",
    "spectrograms_train[0].shape"
   ],
   "id": "2c4d6c90ed4b13e2",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:43:42.134615Z",
     "start_time": "2024-09-01T17:43:41.709386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = GunshotDataset(spectrograms_train, sample_rates_train, labels_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ],
   "id": "f0e1bd47b6bbd7cc",
   "execution_count": 96,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:43:42.615504Z",
     "start_time": "2024-09-01T17:43:42.604485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_std = {'mean': dataset.mean, 'std': dataset.std}\n",
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump(mean_std, f)\n",
    "\n",
    "# Save using torch\n",
    "th.save({'mean': dataset.mean, 'std': dataset.std}, 'mean_std.pth')"
   ],
   "id": "48a2602cdc9536de",
   "execution_count": 97,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:43:43.780595Z",
     "start_time": "2024-09-01T17:43:43.777445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "id": "a9316a61fd5e17ac",
   "execution_count": 98,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:11:50.473165Z",
     "start_time": "2024-09-01T18:11:50.459301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_features, valid_labels, epochs=10, thresholds=None, mean=None, std=None, patience=3):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)  # Define a range of thresholds to test\n",
    "\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_threshold = 0.0\n",
    "    best_score = 0.0\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Normalize features\n",
    "            features = (features - mean) / std\n",
    "\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        best_epoch_threshold, current_score = evaluate_model(model, valid_features, valid_labels, thresholds, mean, std)\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_threshold = best_epoch_threshold\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best F1 score: {best_score:.4f}, model saved.\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        print(f\"TEST best_f1: {best_score} with best threshold: {best_threshold}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"No improvement in F1 score for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Compute and display the confusion matrix on the validation set\n",
    "    cm = compute_confusion_matrix(model, valid_features, valid_labels, best_threshold, mean, std)\n",
    "    display_confusion_matrix(cm)\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "def evaluate_model(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                all_predictions.append(predictions)\n",
    "                all_labels.append(label.item())\n",
    "\n",
    "            # Calculate F1 score\n",
    "            avg_f1_score = f1_score(all_labels, all_predictions)\n",
    "\n",
    "            if avg_f1_score > best_f1_score:\n",
    "                best_f1_score = avg_f1_score\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1_score\n",
    "\n",
    "def compute_confusion_matrix(model, features, labels, threshold, mean, std):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        for feature, label in zip(features, labels):\n",
    "            feature = feature.to(device)\n",
    "            label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "            # Normalize feature\n",
    "            feature = (feature - mean) / std\n",
    "\n",
    "            # Get model predictions\n",
    "            output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "            # Apply threshold\n",
    "            predictions = (output >= threshold).astype(float)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    return cm\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='magma')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_accuracy(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_accuracies = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).to(device)  # Ensure label is a tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score([label.item()], [predictions.item()])\n",
    "\n",
    "                all_accuracies.append(accuracy)\n",
    "\n",
    "            avg_accuracy = np.mean(all_accuracies)\n",
    "            if avg_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_accuracy\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_accuracy"
   ],
   "id": "3320eddc522c604c",
   "execution_count": 127,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:14:12.743385Z",
     "start_time": "2024-09-01T18:11:53.588064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "best_threshold, best_f1 = train_model(model, optimizer, criterion, dataloader, spectrograms_test, labels_test, epochs=25, thresholds=None, mean=dataset.mean, std=dataset.std)"
   ],
   "id": "4f0f9dd0e70ce30e",
   "execution_count": 128,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:47.164977Z",
     "start_time": "2024-09-02T14:12:47.133467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=15, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with th.no_grad():\n",
    "        predictions = []\n",
    "\n",
    "        # Prepare features\n",
    "        num_frames = feature.shape[2]\n",
    "        feature = feature.to(device)\n",
    "        feature = (feature - mean) / std  # Normalize the feature\n",
    "\n",
    "        # Loop through non-overlapping frames\n",
    "        for j in range(0, num_frames - frame_size + 1, 1):\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append(output)\n",
    "\n",
    "        res = []\n",
    "        for idx in range(len(predictions)):\n",
    "            if predictions[idx] >= threshold:\n",
    "                print(idx, predictions[idx])\n",
    "                time_in_seconds = idx * utils.HOP_LENGTH / utils.SAMPLING_RATE\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds))\n",
    "\n",
    "    return res"
   ],
   "id": "4af52a3416d925ab",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:47.754004Z",
     "start_time": "2024-09-02T14:12:47.741286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])\n",
    "# spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Many Men (Wish Death) (Dirty Version).mp3'])"
   ],
   "id": "8fbe732d2b2fad65",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:12:48.409580Z",
     "start_time": "2024-09-02T14:12:48.397265Z"
    }
   },
   "cell_type": "code",
   "source": "spectrograms[0].shape",
   "id": "d391d38ddf160293",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:27:23.514723Z",
     "start_time": "2024-09-01T18:27:23.509417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load mean and std from file\n",
    "with open('./mean_std.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mean = data['mean']\n",
    "    std = data['std']"
   ],
   "id": "5894fb90a87d48e4",
   "execution_count": 131,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:27:27.091552Z",
     "start_time": "2024-09-01T18:27:23.517588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std)"
   ],
   "id": "35d3715bff1ff315",
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:27:33.925651Z",
     "start_time": "2024-09-01T18:27:33.923054Z"
    }
   },
   "cell_type": "code",
   "source": "best_threshold",
   "id": "2e406a68ed7aa9bb",
   "execution_count": 133,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:27:34.628874Z",
     "start_time": "2024-09-01T18:27:34.625415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for time in predicted_times:\n",
    "    print(f\"Prediction at {time[0]} minutes and {time[1]} seconds\")"
   ],
   "id": "4cdcc9bea06e8cf",
   "execution_count": 134,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "91a00824469a918c",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
