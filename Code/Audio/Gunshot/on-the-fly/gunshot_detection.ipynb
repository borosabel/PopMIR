{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:14.428922Z",
     "start_time": "2024-10-13T17:08:14.332528Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:16.573834Z",
     "start_time": "2024-10-13T17:08:14.440496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "88d53b2f860b7b93",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:16.577873Z",
     "start_time": "2024-10-13T17:08:16.575838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gunshot_df = pd.read_csv(\"/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Audio/Gunshot/csv_combined/filtered_gunshot_metadata.csv\")\n",
    "# gunshot_audio_dir = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/edge-collected-gunshot-audio'"
   ],
   "id": "add64faabd017fda",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:16.584617Z",
     "start_time": "2024-10-13T17:08:16.579290Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_glock_df = pd.read_csv('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Audio/Gunshot/on-the-fly/filtered_gunshot_metadata_glocks.csv')",
   "id": "5a139681a9ef09b0",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:19.973021Z",
     "start_time": "2024-10-13T17:08:16.586733Z"
    }
   },
   "cell_type": "code",
   "source": "music_df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data_w_topics_w_features.xlsx', engine='openpyxl')",
   "id": "f19e5dd170cf1fd",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:19.979077Z",
     "start_time": "2024-10-13T17:08:19.974261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_train_df, music_valid_df = train_test_split(music_df, test_size=0.2, random_state=42)\n",
    "gunshot_train_df, gunshot_valid_df = train_test_split(filtered_glock_df, test_size=0.2, random_state=42)"
   ],
   "id": "15e62fbf87ff65d6",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:20.006198Z",
     "start_time": "2024-10-13T17:08:19.981178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)  # Shape: (batch_size, channels, height, width)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "bc413293e1ce9d60",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:22.133604Z",
     "start_time": "2024-10-13T17:08:22.130259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# music_paths = music_df['Path'].tolist()\n",
    "# self.gunshot_paths = gunshot_df['filename'].tolist()\n",
    "# self.gunshot_truth = gunshot_df['gunshot_location_in_seconds'].apply(\n",
    "#     lambda x: utils.preprocess_gunshot_times(x, include_first_gunshot_only=True)\n",
    "# ).tolist()\n",
    "# \n",
    "# music_path = music_train_df.iloc[0]['Path']\n",
    "# gunshot_path, gunshot_locations = gunshot_valid_df.iloc[0]['filename'], gunshot_valid_df.iloc[0]['gunshot_location_in_seconds']\n",
    "# gunshot_locations = utils.preprocess_gunshot_times(gunshot_locations, include_first_gunshot_only=True)"
   ],
   "id": "729c2072b04f76d1",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:22.457782Z",
     "start_time": "2024-10-13T17:08:22.455157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importlib.reload(utils)\n",
    "# \n",
    "# utils.combine_music_and_gunshot(music_path, gunshot_path, gunshot_locations[0])"
   ],
   "id": "ebb7458177db418d",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:08:22.729870Z",
     "start_time": "2024-10-13T17:08:22.725407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_row = music_train_df.iloc[0]\n",
    "gunshot_row = gunshot_train_df.iloc[0]\n",
    "\n",
    "music_path, sr, = music_row['Path'], music_row['Sample Rate (Hz)']\n",
    "gunshot_path, gunshot_locations, num_gunshots = gunshot_row['filename'], gunshot_row['gunshot_location_in_seconds'], gunshot_row['num_gunshots']"
   ],
   "id": "9fd62c46560381a1",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:09:37.888816Z",
     "start_time": "2024-10-13T17:09:37.882703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, music_df, gunshot_df, excerpt_len=5.0, gunshot_placement_sec=2.0, gunshot_prob=1.0, min_db=3, max_db=5, max_non_gunshot_samples=1, mean=None, std=None):\n",
    "        \"\"\"\n",
    "        :param music_df: DataFrame containing paths to music files.\n",
    "        :param gunshot_df: DataFrame containing paths to gunshot files and timing info.\n",
    "        :param excerpt_len: Length of the music segment in seconds.\n",
    "        :param gunshot_placement_sec: Time in seconds where to place the gunshot in the music.\n",
    "        :param gunshot_prob: Probability of adding a gunshot to the segment.\n",
    "        :param min_db: Minimum gain (in dB) to apply to the gunshot.\n",
    "        :param max_db: Maximum gain (in dB) to apply to the gunshot.\n",
    "        :param max_non_gunshot_samples: Max number of non-gunshot samples to extract when no gunshots are present.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.music_paths = music_df['Path'].tolist()\n",
    "        self.gunshot_paths = gunshot_df['filename'].tolist()\n",
    "        self.gunshot_truth = gunshot_df['gunshot_location_in_seconds'].apply(\n",
    "            lambda x: utils.preprocess_gunshot_times(x, include_first_gunshot_only=True)\n",
    "        ).tolist()\n",
    "        print(self.gunshot_truth[0])\n",
    "        self.excerpt_len = excerpt_len\n",
    "        self.gunshot_placement_sec = gunshot_placement_sec\n",
    "        self.gunshot_prob = gunshot_prob\n",
    "        self.min_db = min_db\n",
    "        self.max_db = max_db\n",
    "        self.max_non_gunshot_samples = max_non_gunshot_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn_music = self.music_paths[idx]\n",
    "        add_gunshot = (np.random.rand() < self.gunshot_prob)\n",
    "        sample_rate = 44100\n",
    "\n",
    "        if add_gunshot:\n",
    "            gunshot_idx = np.random.randint(0, len(self.gunshot_paths) - 1)\n",
    "            fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "            gunshot_times = self.gunshot_truth[gunshot_idx][0]\n",
    "\n",
    "            # Combine music and gunshot\n",
    "            music_segment, sr = utils.combine_music_and_gunshot(\n",
    "                music_file=fn_music,\n",
    "                gunshot_file=fn_gunshot,\n",
    "                gunshot_time=gunshot_times,\n",
    "                gunshot_volume_increase_dB=self.max_db,\n",
    "                gunshot_placement_sec=self.gunshot_placement_sec,\n",
    "                excerpt_len_sec=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 1\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label, gunshot_times)\n",
    "        else:\n",
    "            # Extract a segment of music without gunshots\n",
    "            music_segment, sr = utils.extract_music_segment(\n",
    "                music_file=fn_music,\n",
    "                excerpt_len=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 0\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label)\n",
    "\n",
    "        if not spectrograms or not labels:\n",
    "            raise ValueError(\"Spectrograms or labels are empty after preprocessing\")\n",
    "\n",
    "        return spectrograms[0], labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.music_paths)"
   ],
   "id": "499b239c9ba38101",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:09:38.213914Z",
     "start_time": "2024-10-13T17:09:38.206031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "# Create training dataset\n",
    "train_dataset = GunshotDataset(music_train_df, gunshot_train_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=0.5)\n",
    "\n",
    "# Create validation dataset\n",
    "valid_dataset = GunshotDataset(music_valid_df, gunshot_valid_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=0.5)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for validation (no need to shuffle validation data)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "56b20b516bce2652",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T09:39:00.067471Z",
     "start_time": "2024-09-28T09:39:00.033780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "use_cuda = th.cuda.is_available()\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_loader, epochs=10, mean=None, std=None, patience=3):\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    best_score = 0.0\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    if use_cuda:\n",
    "        scaler = th.cuda.amp.GradScaler()  # For mixed precision training\n",
    "    else:\n",
    "        scaler = None  # No need for GradScaler on CPU\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add tqdm progress bar for training loop\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}] Training\")\n",
    "\n",
    "        for features, labels in train_loader_tqdm:\n",
    "            features, labels = features.to(device), labels.to(device).float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            features = (features - mean) / std\n",
    "\n",
    "            if use_cuda:\n",
    "                with th.cuda.amp.autocast():\n",
    "                    outputs = model(features).view(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(features).view(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "\n",
    "            # Update tqdm description with current loss\n",
    "            train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_score = evaluate_model_simple(model, valid_loader, mean, std)\n",
    "\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best ROC AUC score: {best_score:.4f}, model saved.\")\n",
    "            # Save the model if desired\n",
    "            # torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"No improvement in ROC AUC score for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # After training, find the optimal threshold\n",
    "    best_threshold = find_optimal_threshold_after_training(model, valid_loader, mean, std)\n",
    "\n",
    "    # Compute and display the confusion matrix\n",
    "    cm = compute_confusion_matrix(model, valid_loader, best_threshold, mean, std)\n",
    "    display_confusion_matrix(cm)\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "\n",
    "def evaluate_model_simple(model, valid_loader, mean, std):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set using ROC AUC score.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        valid_loader (DataLoader): DataLoader for validation data.\n",
    "        mean (torch.Tensor): Mean for normalization.\n",
    "        std (torch.Tensor): Standard deviation for normalization.\n",
    "\n",
    "    Returns:\n",
    "        auc (float): ROC AUC score on the validation set.\n",
    "    \"\"\"\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Add tqdm progress bar for validation loop\n",
    "    valid_loader_tqdm = tqdm(valid_loader, desc=\"Validation\")\n",
    "\n",
    "    with th.no_grad():\n",
    "        for features, labels in valid_loader_tqdm:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            features = (features - mean) / std\n",
    "            outputs = model(features).view(-1).cpu().numpy()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    auc = roc_auc_score(all_labels, all_outputs)\n",
    "    print(f\"Validation ROC AUC: {auc:.4f}\")\n",
    "    return auc\n",
    "\n",
    "def find_optimal_threshold_after_training(model, valid_loader, mean, std):\n",
    "    \"\"\"\n",
    "    Finds the optimal threshold after training using ROC curve and Youden's J statistic.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        valid_loader (DataLoader): DataLoader for validation data.\n",
    "        mean (torch.Tensor): Mean for normalization.\n",
    "        std (torch.Tensor): Standard deviation for normalization.\n",
    "\n",
    "    Returns:\n",
    "        optimal_threshold (float): Optimal threshold value.\n",
    "    \"\"\"\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Add tqdm progress bar for validation loop\n",
    "    valid_loader_tqdm = tqdm(valid_loader, desc=\"Finding Optimal Threshold\")\n",
    "\n",
    "    with th.no_grad():\n",
    "        for features, labels in valid_loader_tqdm:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            features = (features - mean) / std\n",
    "            outputs = model(features).view(-1).cpu().numpy()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_outputs)\n",
    "    youdens_j = tpr - fpr\n",
    "    idx = np.argmax(youdens_j)\n",
    "    optimal_threshold = thresholds[idx]\n",
    "\n",
    "    print(f\"Optimal threshold found: {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def compute_confusion_matrix(model, valid_loader, threshold, mean, std):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix using batch processing.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        valid_loader (DataLoader): DataLoader for validation data.\n",
    "        threshold (float): Threshold to convert probabilities to binary predictions.\n",
    "        mean (torch.Tensor): Mean for normalization.\n",
    "        std (torch.Tensor): Standard deviation for normalization.\n",
    "\n",
    "    Returns:\n",
    "        cm (numpy.ndarray): Confusion matrix.\n",
    "    \"\"\"\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Add tqdm progress bar for validation loop\n",
    "    valid_loader_tqdm = tqdm(valid_loader, desc=\"Computing Confusion Matrix\")\n",
    "\n",
    "    with th.no_grad():\n",
    "        for features, labels in valid_loader_tqdm:\n",
    "            features = features.to(device)\n",
    "            labels = labels.cpu().numpy()\n",
    "            features = (features - mean) / std\n",
    "            outputs = model(features).view(-1).cpu().numpy()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    predictions = (all_outputs >= threshold).astype(int)\n",
    "    cm = confusion_matrix(all_labels, predictions)\n",
    "\n",
    "    return cm\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    \"\"\"\n",
    "    Displays the confusion matrix using matplotlib.\n",
    "\n",
    "    Parameters:\n",
    "        cm (numpy.ndarray): Confusion matrix.\n",
    "    \"\"\"\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='magma')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ],
   "id": "4a4106b1bfa731b4",
   "execution_count": 109,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T09:39:05.267335Z",
     "start_time": "2024-09-28T09:39:00.719826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_mean_std(dataloader):\n",
    "    \"\"\"Compute mean and std of the entire dataset with progress tracking using tqdm.\"\"\"\n",
    "    # Use tqdm to wrap the dataloader and show progress\n",
    "    l = []\n",
    "    for features, _ in tqdm(dataloader, desc=\"Computing mean and std\"):\n",
    "        l += features\n",
    "    tmp = th.cat(l)\n",
    "    mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "    std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(train_loader)\n",
    "\n",
    "# Move mean and std to the device for training\n",
    "mean = mean.to(device) \n",
    "std = std.to(device)"
   ],
   "id": "27b878f8e3dbd8e0",
   "execution_count": 110,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:06:29.288775Z",
     "start_time": "2024-09-28T09:39:06.719087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = th.nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "best_threshold, best_score = train_model(\n",
    "    model, optimizer, criterion, train_loader, valid_loader,\n",
    "    epochs=10, mean=mean, std=std, patience=3\n",
    ")\n",
    "\n",
    "print(f\"Training completed. Best ROC AUC: {best_score:.4f}, Optimal Threshold: {best_threshold:.4f}\")"
   ],
   "id": "e3ed13fe35ff7734",
   "execution_count": 111,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:21:02.804842Z",
     "start_time": "2024-09-28T15:21:02.786735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=utils.NUM_FRAMES, sampling_rate=utils.SAMPLING_RATE, hop_length=utils.HOP_LENGTH, mean=None, std=None, step_size=None, filter_time_sec=1):\n",
    "    \"\"\"\n",
    "    Manually evaluate the model on an audio feature, returning time positions where gunshots are detected.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        feature: The feature (e.g., spectrogram) to evaluate.\n",
    "        threshold: The prediction threshold for gunshots.\n",
    "        frame_size: Number of frames to use in each evaluation.\n",
    "        sampling_rate: Audio sampling rate.\n",
    "        hop_length: Hop length in samples for each frame.\n",
    "        mean: Mean for normalization.\n",
    "        std: Standard deviation for normalization.\n",
    "        step_size: Step size for moving through frames (default: frame_size // 2).\n",
    "        filter_time_sec: Time (in seconds) to filter out close consecutive predictions.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (minutes, seconds, output) where gunshots are detected along with the model's output.\n",
    "    \"\"\"\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Normalize feature\n",
    "    feature = feature.to(device)\n",
    "    feature = (feature - mean) / std\n",
    "\n",
    "    num_frames = feature.shape[2]\n",
    "\n",
    "    # If step_size is not specified, default to half the frame size\n",
    "    if step_size is None:\n",
    "        # step_size = frame_size // 2  # Adjust step_size if necessary\n",
    "        step_size = 1\n",
    "\n",
    "    total_iterations = 0  # To count the iterations\n",
    "\n",
    "    with th.no_grad():\n",
    "        # Loop through overlapping frames with smaller step size\n",
    "        for j in range(0, num_frames - frame_size + 1, step_size):\n",
    "            total_iterations += 1\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append((output, start))  # Keep track of output and start position\n",
    "\n",
    "        return predictions\n",
    "\n",
    "        # Sort predictions by the time index\n",
    "        res = []\n",
    "        for output, start in predictions:\n",
    "            if output >= threshold:\n",
    "                time_in_seconds = start * hop_length / sampling_rate\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds, time_in_seconds, output))  # Add output to the result\n",
    "\n",
    "    # Filter out close consecutive detections\n",
    "    filtered_res = []\n",
    "    last_detection_time = -float('inf')  # Initialize with negative infinity to accept the first detection\n",
    "\n",
    "    for minutes, seconds, time_in_seconds, output in res:\n",
    "        if time_in_seconds - last_detection_time >= filter_time_sec:\n",
    "            # Append with output value included\n",
    "            filtered_res.append((minutes, seconds, output))\n",
    "            last_detection_time = time_in_seconds  # Update the last detected time\n",
    "\n",
    "    # Return results with raw model output for comparison\n",
    "    return filtered_res"
   ],
   "id": "ffd6860128d82ca1",
   "execution_count": 114,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:19:23.145445Z",
     "start_time": "2024-09-28T15:19:15.367459Z"
    }
   },
   "cell_type": "code",
   "source": "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])",
   "id": "c9dcaec460ca02e4",
   "execution_count": 112,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:21:04.082617Z",
     "start_time": "2024-09-28T15:21:04.038397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = manual_evaluate_test(model, spectrograms, threshold=best_threshold, mean=mean, std=std, step_size=1,\n",
    "                                   filter_time_sec=1.5)"
   ],
   "id": "da81a1f5596b5af5",
   "execution_count": 115,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a9c8801202d4a480",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
