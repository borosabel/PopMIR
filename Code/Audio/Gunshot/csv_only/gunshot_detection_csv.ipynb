{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:35.683748Z",
     "start_time": "2024-09-03T16:03:35.675208Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 135,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:35.814941Z",
     "start_time": "2024-09-03T16:03:35.806704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "b2a6f713e1a36061",
   "execution_count": 136,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:36.035851Z",
     "start_time": "2024-09-03T16:03:36.024522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        # Dummy input to calculate the output size after conv and pooling layers\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)  # Shape: (batch_size, channels, height, width)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "\n",
    "        # Flatten the dummy output to find the size for the first fully connected layer\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "        # print(f\"Calculated output size for fc1: {output_size}\")  # Debugging line\n",
    "\n",
    "        # Adjust the fully connected layer input size based on the calculated output size\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(f\"Shape after conv and pooling layers: {x.shape}\")  # Debugging line\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor while keeping the batch size\n",
    "        # print(f\"Shape after flattening: {x.shape}\")  # Debugging line\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "bb96b05a72df2670",
   "execution_count": 137,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:36.472240Z",
     "start_time": "2024-09-03T16:03:36.454976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y in zip(spectograms, sample_rates, targets):\n",
    "            X_frames, y_frames = utils.make_frames(X, y)\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        tmp = th.cat(self.X)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "id": "6ef48c751d5a366b",
   "execution_count": 138,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:38.771044Z",
     "start_time": "2024-09-03T16:03:38.725875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshots_paths = pd.read_csv('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/gunshot-audio-all-metadata.csv')\n",
    "gunshots = gunshots_paths[['filename', 'num_gunshots', 'gunshot_location_in_seconds']].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Function to preprocess gunshot start times, converting strings to lists of floats\n",
    "def preprocess_gunshot_times(gunshot_times, include_first_gunshot_only=False):\n",
    "    # Remove multiple spaces\n",
    "    gunshot_times = re.sub(r'\\s+', ' ', gunshot_times).strip()\n",
    "\n",
    "    # Insert commas between numbers if missing\n",
    "    gunshot_times = re.sub(r'(?<=\\d)\\s(?=\\d)', ', ', gunshot_times)\n",
    "\n",
    "    # Ensure there are no trailing commas\n",
    "    gunshot_times = gunshot_times.replace(', ]', ']')\n",
    "\n",
    "    # Safely evaluate the string as a list\n",
    "    try:\n",
    "        gunshot_list = ast.literal_eval(gunshot_times)\n",
    "        if include_first_gunshot_only and isinstance(gunshot_list, list) and gunshot_list:\n",
    "            return [gunshot_list[0]]  # Return only the first gunshot time\n",
    "        return gunshot_list\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Return an empty list if the string is not a valid list\n",
    "        return []\n",
    "\n",
    "# Function to change the filename by adding the root path and appending .wav extension\n",
    "def change_filename(filename, root_path):\n",
    "    return os.path.join(root_path, filename + '.wav')\n",
    "\n",
    "# Define the root path\n",
    "root_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/edge-collected-gunshot-audio/'\n",
    "\n",
    "# Boolean flag to control if only the first gunshot time should be included\n",
    "include_first_gunshot_only = True\n",
    "\n",
    "# Apply the function to preprocess the 'gunshot_location_in_seconds' column with the boolean flag\n",
    "gunshots['gunshot_location_in_seconds'] = gunshots['gunshot_location_in_seconds'].apply(\n",
    "    lambda x: preprocess_gunshot_times(x, include_first_gunshot_only)\n",
    ")\n",
    "\n",
    "# If include_first_gunshot_only is True, set 'num_gunshots' to 1\n",
    "if include_first_gunshot_only:\n",
    "    gunshots['num_gunshots'] = gunshots['gunshot_location_in_seconds'].apply(lambda x: len(x))\n",
    "\n",
    "# Update the 'filename' column with the full path\n",
    "gunshots['filename'] = gunshots['filename'].apply(lambda x: change_filename(x, root_path))\n",
    "\n",
    "# Add the label column\n",
    "gunshots['label'] = 1"
   ],
   "id": "8f4c063c75f23fca",
   "execution_count": 139,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:39.273885Z",
     "start_time": "2024-09-03T16:03:39.219632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_gunshot_data_paths = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/Combined'\n",
    "\n",
    "def generate_no_gunshot_dataframe(no_gunshot_data_paths, limit=None):\n",
    "    # Initialize a list to store the records\n",
    "    records = []\n",
    "    count = 0\n",
    "\n",
    "    # Recursively loop through all files in the no-gunshot folder\n",
    "    for root, dirs, files in os.walk(no_gunshot_data_paths):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.mp3') and 'without_gunshot' in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # For no-gunshot files\n",
    "                gunshot_flag = 0\n",
    "                label = 0\n",
    "                timestampt = []  # Empty list for no gunshot\n",
    "\n",
    "                # Append the record to the list\n",
    "                records.append([file_path, timestampt, gunshot_flag, label])\n",
    "                count += 1\n",
    "\n",
    "                if limit and count >= limit:\n",
    "                    break\n",
    "\n",
    "        if limit and count >= limit:\n",
    "            break\n",
    "\n",
    "    # Create a DataFrame from the records\n",
    "    df = pd.DataFrame(records, columns=['filename', 'gunshot_location_in_seconds', 'num_gunshots', 'label'])\n",
    "    return df\n",
    "\n",
    "# Limit the number of no-gunshot samples to match the gunshot samples\n",
    "no_gunshot_limit = len(gunshots)\n",
    "\n",
    "# Generate the no-gunshot DataFrame\n",
    "no_gunshots_df = generate_no_gunshot_dataframe(no_gunshot_data_paths, limit=no_gunshot_limit)\n",
    "\n",
    "# Concatenate the gunshot and no-gunshot DataFrames\n",
    "combined_df = pd.concat([gunshots, no_gunshots_df], ignore_index=True)\n",
    "\n",
    "# Optional: shuffle the combined DataFrame to mix gunshot and no-gunshot samples\n",
    "df = combined_df.sample(frac=1).reset_index(drop=True)"
   ],
   "id": "f6e6685860db66d6",
   "execution_count": 140,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:39.736663Z",
     "start_time": "2024-09-03T16:03:39.725346Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "af46a84e902feb8b",
   "execution_count": 141,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:40.172377Z",
     "start_time": "2024-09-03T16:03:40.169180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = df[['filename', 'num_gunshots', 'gunshot_location_in_seconds']]\n",
    "labels = df[['label']]"
   ],
   "id": "e9b5a9804dc2e39d",
   "execution_count": 142,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:40.663910Z",
     "start_time": "2024-09-03T16:03:40.660298Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths, X_test_paths, y_train_paths, y_test_paths = train_test_split(files, labels, test_size=0.3, random_state=42)",
   "id": "f20258abc0507e58",
   "execution_count": 143,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:03:41.216895Z",
     "start_time": "2024-09-03T16:03:41.209739Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths",
   "id": "34fd1dbe2a7db3ef",
   "execution_count": 144,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:04:10.700154Z",
     "start_time": "2024-09-03T16:03:41.991535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms_train, sample_rates_train, labels_train = utils.preprocess_audio_train(X_train_paths, max_non_gunshot_samples=1)\n",
    "spectrograms_test, sample_rates_test, labels_test = utils.preprocess_audio_train(X_test_paths, max_non_gunshot_samples=1)"
   ],
   "id": "bbb663192d157643",
   "execution_count": 145,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:04:13.210520Z",
     "start_time": "2024-09-03T16:04:13.206366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 dimensions of mel-spectograms with 80 mel bands and 15 frames.\n",
    "spectrograms_train[0].shape"
   ],
   "id": "d1def25db6e5a412",
   "execution_count": 146,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:04:13.892023Z",
     "start_time": "2024-09-03T16:04:13.753517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = GunshotDataset(spectrograms_train, sample_rates_train, labels_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ],
   "id": "7923514ea6769e74",
   "execution_count": 147,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_std = {'mean': dataset.mean, 'std': dataset.std}\n",
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump(mean_std, f)\n",
    "\n",
    "# Save using torch\n",
    "th.save({'mean': dataset.mean, 'std': dataset.std}, 'mean_std.pth')"
   ],
   "id": "62bd3ce7d91c66f1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T16:00:13.934157Z",
     "start_time": "2024-09-03T16:00:13.934054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "id": "c54e3e4b38a25bae",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:24:20.107502Z",
     "start_time": "2024-09-03T15:24:20.095325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_features, valid_labels, epochs=10, thresholds=None, mean=None, std=None, patience=3):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)  # Define a range of thresholds to test\n",
    "\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_threshold = 0.0\n",
    "    best_score = 0.0\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Normalize features\n",
    "            features = (features - mean) / std\n",
    "\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        best_epoch_threshold, current_score = evaluate_model(model, valid_features, valid_labels, thresholds, mean, std)\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_threshold = best_epoch_threshold\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best F1 score: {best_score:.4f}, model saved.\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        print(f\"TEST best_f1: {best_score} with best threshold: {best_threshold}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"No improvement in F1 score for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Compute and display the confusion matrix on the validation set\n",
    "    cm = compute_confusion_matrix(model, valid_features, valid_labels, best_threshold, mean, std)\n",
    "    display_confusion_matrix(cm)\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "def evaluate_model(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                all_predictions.append(predictions)\n",
    "                all_labels.append(label.item())\n",
    "\n",
    "            # Calculate F1 score\n",
    "            avg_f1_score = f1_score(all_labels, all_predictions)\n",
    "\n",
    "            if avg_f1_score > best_f1_score:\n",
    "                best_f1_score = avg_f1_score\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1_score\n",
    "\n",
    "def compute_confusion_matrix(model, features, labels, threshold, mean, std):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        for feature, label in zip(features, labels):\n",
    "            feature = feature.to(device)\n",
    "            label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "            # Normalize feature\n",
    "            feature = (feature - mean) / std\n",
    "\n",
    "            # Get model predictions\n",
    "            output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "            # Apply threshold\n",
    "            predictions = (output >= threshold).astype(float)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    return cm\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='magma')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_accuracy(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_accuracies = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).to(device)  # Ensure label is a tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score([label.item()], [predictions.item()])\n",
    "\n",
    "                all_accuracies.append(accuracy)\n",
    "\n",
    "            avg_accuracy = np.mean(all_accuracies)\n",
    "            if avg_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_accuracy\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_accuracy"
   ],
   "id": "27d0f04e6d47b825",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:29:32.265791Z",
     "start_time": "2024-09-03T15:24:26.537177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "best_threshold, best_f1 = train_model(model, optimizer, criterion, dataloader, spectrograms_test, labels_test, epochs=25, thresholds=None, mean=dataset.mean, std=dataset.std)"
   ],
   "id": "1929893a092f7d16",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:16.891984Z",
     "start_time": "2024-09-03T15:30:16.883716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=utils.NUM_FRAMES, sampling_rate=utils.SAMPLING_RATE, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Normalize feature\n",
    "    feature = feature.to(device)\n",
    "    feature = (feature - mean) / std\n",
    "\n",
    "    num_frames = feature.shape[2]\n",
    "\n",
    "    total_iterations = 0  # To count the iterations\n",
    "\n",
    "    with th.no_grad():\n",
    "        # Loop through non-overlapping frames\n",
    "        for j in range(0, num_frames - frame_size + 1, frame_size):\n",
    "            total_iterations += 1\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append(output)\n",
    "\n",
    "        res = []\n",
    "        for idx in range(len(predictions)):\n",
    "            if predictions[idx] >= threshold:\n",
    "                time_in_seconds = idx * frame_size * utils.HOP_LENGTH / sampling_rate\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds))\n",
    "\n",
    "    return res"
   ],
   "id": "daf2c417a1b6507a",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:28.041452Z",
     "start_time": "2024-09-03T15:30:25.611542Z"
    }
   },
   "cell_type": "code",
   "source": "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])",
   "id": "d52250681fb3a243",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:30.404346Z",
     "start_time": "2024-09-03T15:30:30.399643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load mean and std from file\n",
    "with open('./mean_std.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mean = data['mean']\n",
    "    std = data['std']"
   ],
   "id": "f834a8d8e4eba374",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:35.554030Z",
     "start_time": "2024-09-03T15:30:35.218915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std)"
   ],
   "id": "5989df8a0e3a3f4f",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:39.809052Z",
     "start_time": "2024-09-03T15:30:39.806804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for time in predicted_times:\n",
    "    print(f\"Prediction at {time[0]} minutes and {time[1]} seconds\")"
   ],
   "id": "3db68bc957f818b4",
   "execution_count": 53,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:30:53.103686Z",
     "start_time": "2024-09-03T15:30:49.827391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Many Men (Wish Death) (Dirty Version).mp3'])\n",
    "\n",
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std)\n",
    "\n",
    "for time in predicted_times:\n",
    "    print(f\"Prediction at {time[0]} minutes and {time[1]} seconds\")"
   ],
   "id": "30d7e3255e2561f8",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "44b938029810b7a5",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
