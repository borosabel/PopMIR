{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:46.624084Z",
     "start_time": "2024-09-03T14:56:46.615629Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:46.864311Z",
     "start_time": "2024-09-03T14:56:46.853922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "501168c19fd7dd9",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:47.262Z",
     "start_time": "2024-09-03T14:56:47.241948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        # Dummy input to calculate the output size after conv and pooling layers\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)  # Shape: (batch_size, channels, height, width)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "\n",
    "        # Flatten the dummy output to find the size for the first fully connected layer\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "        # print(f\"Calculated output size for fc1: {output_size}\")  # Debugging line\n",
    "\n",
    "        # Adjust the fully connected layer input size based on the calculated output size\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(f\"Shape after conv and pooling layers: {x.shape}\")  # Debugging line\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor while keeping the batch size\n",
    "        # print(f\"Shape after flattening: {x.shape}\")  # Debugging line\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "aaf345589d8df698",
   "execution_count": 96,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:47.884458Z",
     "start_time": "2024-09-03T14:56:47.878740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y in zip(spectograms, sample_rates, targets):\n",
    "            X_frames, y_frames = utils.make_frames(X, y)\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        tmp = th.cat(self.X)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "id": "8be1747a4602a52c",
   "execution_count": 97,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:48.422723Z",
     "start_time": "2024-09-03T14:56:48.365436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_data_paths = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csvfree'\n",
    "no_gunshot_data_paths = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/Combined'\n",
    "\n",
    "def generate_file_dataframe(gunshot_data_paths, no_gunshot_data_paths):\n",
    "    # Initialize a list to store the records\n",
    "    records = []\n",
    "\n",
    "    # Recursively loop through all files in the gunshot folder\n",
    "    gunshot_count = 0\n",
    "    for root, dirs, files in os.walk(gunshot_data_paths):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):  # Only consider wav files\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # For gunshot files\n",
    "                gunshot_flag = 1\n",
    "                label = 1\n",
    "                timestampt = [0.5]  # Start time for gunshot\n",
    "\n",
    "                # Append the record to the list\n",
    "                records.append([file_path, timestampt, gunshot_flag, label])\n",
    "                gunshot_count += 1\n",
    "\n",
    "    # Recursively loop through all files in the no-gunshot folder\n",
    "    no_gunshot_count = 0\n",
    "    for root, dirs, files in os.walk(no_gunshot_data_paths):\n",
    "        for filename in files:\n",
    "            if no_gunshot_count >= gunshot_count:\n",
    "                break  # Stop adding no-gunshot samples once the count matches gunshot samples\n",
    "            if filename.endswith('.mp3') and 'without_gunshot' in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # For no-gunshot files\n",
    "                gunshot_flag = 0\n",
    "                label = 0\n",
    "                timestampt = []  # Empty list for no gunshot\n",
    "\n",
    "                # Append the record to the list\n",
    "                records.append([file_path, timestampt, gunshot_flag, label])\n",
    "                no_gunshot_count += 1\n",
    "\n",
    "    # Create a DataFrame from the records\n",
    "    df = pd.DataFrame(records, columns=['filename', 'gunshot_location_in_seconds', 'num_gunshots', 'label'])\n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df = generate_file_dataframe(gunshot_data_paths, no_gunshot_data_paths)"
   ],
   "id": "ee66a29cbccdcd1e",
   "execution_count": 98,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:48.988031Z",
     "start_time": "2024-09-03T14:56:48.981709Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "6765055dc1f35662",
   "execution_count": 99,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:49.596941Z",
     "start_time": "2024-09-03T14:56:49.593271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = df[['filename', 'num_gunshots', 'gunshot_location_in_seconds']]\n",
    "labels = df[['label']]"
   ],
   "id": "a8546a16dc997acd",
   "execution_count": 100,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:50.013552Z",
     "start_time": "2024-09-03T14:56:50.009480Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths, X_test_paths, y_train_paths, y_test_paths = train_test_split(files, labels, test_size=0.3, random_state=42)",
   "id": "df07699de679aab6",
   "execution_count": 101,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:56:50.368655Z",
     "start_time": "2024-09-03T14:56:50.361197Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_paths",
   "id": "83d94bf08938618f",
   "execution_count": 102,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:14.371904Z",
     "start_time": "2024-09-03T15:02:34.418012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms_train, sample_rates_train, labels_train = utils.preprocess_audio_train(X_train_paths, max_non_gunshot_samples=5)\n",
    "spectrograms_test, sample_rates_test, labels_test = utils.preprocess_audio_train(X_test_paths, max_non_gunshot_samples=1)"
   ],
   "id": "9e4e95486d70d6ee",
   "execution_count": 124,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:14.378304Z",
     "start_time": "2024-09-03T15:03:14.373402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 dimensions of mel-spectograms with 80 mel bands and 15 frames.\n",
    "spectrograms_train[0].shape"
   ],
   "id": "97c79f9841b76260",
   "execution_count": 125,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:15.150217Z",
     "start_time": "2024-09-03T15:03:14.379365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = GunshotDataset(spectrograms_train, sample_rates_train, labels_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ],
   "id": "e968be412af2af16",
   "execution_count": 126,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:15.227213Z",
     "start_time": "2024-09-03T15:03:15.201012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_std = {'mean': dataset.mean, 'std': dataset.std}\n",
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump(mean_std, f)\n",
    "\n",
    "# Save using torch\n",
    "th.save({'mean': dataset.mean, 'std': dataset.std}, 'mean_std.pth')"
   ],
   "id": "a17d84b0639dc34a",
   "execution_count": 127,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:15.251934Z",
     "start_time": "2024-09-03T15:03:15.245297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "id": "af2bd8833b6a85b8",
   "execution_count": 128,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:15.275135Z",
     "start_time": "2024-09-03T15:03:15.253754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_features, valid_labels, epochs=10, thresholds=None, mean=None, std=None, patience=3):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)  # Define a range of thresholds to test\n",
    "\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_threshold = 0.0\n",
    "    best_score = 0.0\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Normalize features\n",
    "            features = (features - mean) / std\n",
    "\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        best_epoch_threshold, current_score = evaluate_model(model, valid_features, valid_labels, thresholds, mean, std)\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_threshold = best_epoch_threshold\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best F1 score: {best_score:.4f}, model saved.\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        print(f\"TEST best_f1: {best_score} with best threshold: {best_threshold}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"No improvement in F1 score for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Compute and display the confusion matrix on the validation set\n",
    "    cm = compute_confusion_matrix(model, valid_features, valid_labels, best_threshold, mean, std)\n",
    "    display_confusion_matrix(cm)\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "def evaluate_model(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                all_predictions.append(predictions)\n",
    "                all_labels.append(label.item())\n",
    "\n",
    "            # Calculate F1 score\n",
    "            avg_f1_score = f1_score(all_labels, all_predictions)\n",
    "\n",
    "            if avg_f1_score > best_f1_score:\n",
    "                best_f1_score = avg_f1_score\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1_score\n",
    "\n",
    "def compute_confusion_matrix(model, features, labels, threshold, mean, std):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        for feature, label in zip(features, labels):\n",
    "            feature = feature.to(device)\n",
    "            label = th.tensor(label).float().to(device)  # Ensure label is a float tensor\n",
    "\n",
    "            # Normalize feature\n",
    "            feature = (feature - mean) / std\n",
    "\n",
    "            # Get model predictions\n",
    "            output = model(feature.unsqueeze(0)).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "            # Apply threshold\n",
    "            predictions = (output >= threshold).astype(float)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    return cm\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='magma')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_accuracy(model, features, labels, thresholds, mean, std):\n",
    "    best_threshold = 0.0\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for threshold in thresholds:\n",
    "            all_accuracies = []\n",
    "\n",
    "            for feature, label in zip(features, labels):\n",
    "                feature = feature.to(device)\n",
    "                label = th.tensor(label).to(device)  # Ensure label is a tensor\n",
    "\n",
    "                # Normalize feature\n",
    "                feature = (feature - mean) / std\n",
    "\n",
    "                # Get model predictions\n",
    "                output = model(feature).squeeze().cpu().numpy()  # Add batch dimension\n",
    "\n",
    "                # Apply threshold\n",
    "                predictions = (output >= threshold).astype(float)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score([label.item()], [predictions.item()])\n",
    "\n",
    "                all_accuracies.append(accuracy)\n",
    "\n",
    "            avg_accuracy = np.mean(all_accuracies)\n",
    "            if avg_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_accuracy\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_accuracy"
   ],
   "id": "86a538feb07e8d4b",
   "execution_count": 129,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:03:58.148082Z",
     "start_time": "2024-09-03T15:03:15.277237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "best_threshold, best_f1 = train_model(model, optimizer, criterion, dataloader, spectrograms_test, labels_test, epochs=25, thresholds=None, mean=dataset.mean, std=dataset.std)"
   ],
   "id": "ca72aeeef15efaf",
   "execution_count": 130,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:08.726325Z",
     "start_time": "2024-09-03T15:04:08.719970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=utils.NUM_FRAMES, sampling_rate=utils.SAMPLING_RATE, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Normalize feature\n",
    "    feature = feature.to(device)\n",
    "    feature = (feature - mean) / std\n",
    "\n",
    "    num_frames = feature.shape[2]\n",
    "\n",
    "    total_iterations = 0  # To count the iterations\n",
    "\n",
    "    with th.no_grad():\n",
    "        # Loop through non-overlapping frames\n",
    "        for j in range(0, num_frames - frame_size + 1, frame_size):\n",
    "            total_iterations += 1\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append(output)\n",
    "\n",
    "        res = []\n",
    "        for idx in range(len(predictions)):\n",
    "            if predictions[idx] >= threshold:\n",
    "                time_in_seconds = idx * frame_size * utils.HOP_LENGTH / sampling_rate\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds))\n",
    "\n",
    "    return res"
   ],
   "id": "f4672d453424e084",
   "execution_count": 131,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:11.394163Z",
     "start_time": "2024-09-03T15:04:09.482858Z"
    }
   },
   "cell_type": "code",
   "source": "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])",
   "id": "d4cf5340e0ac554c",
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:11.413266Z",
     "start_time": "2024-09-03T15:04:11.404155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load mean and std from file\n",
    "with open('./mean_std.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mean = data['mean']\n",
    "    std = data['std']"
   ],
   "id": "219e7d546ef2b19c",
   "execution_count": 133,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:11.569871Z",
     "start_time": "2024-09-03T15:04:11.414137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std)"
   ],
   "id": "815b79812832e244",
   "execution_count": 134,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:11.573792Z",
     "start_time": "2024-09-03T15:04:11.571589Z"
    }
   },
   "cell_type": "code",
   "source": "print(best_threshold)",
   "id": "c5cf8fe69e8cf2dd",
   "execution_count": 135,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:11.577623Z",
     "start_time": "2024-09-03T15:04:11.574644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for time in predicted_times:\n",
    "    print(f\"Prediction at {time[0]} minutes and {time[1]} seconds\")"
   ],
   "id": "de8794584b0e041b",
   "execution_count": 136,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T15:04:19.535127Z",
     "start_time": "2024-09-03T15:04:16.292148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Many Men (Wish Death) (Dirty Version).mp3'])\n",
    "\n",
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std)\n",
    "\n",
    "for time in predicted_times:\n",
    "    print(f\"Prediction at {time[0]} minutes and {time[1]} seconds\")"
   ],
   "id": "9426bc2345b4f776",
   "execution_count": 137,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "5810f9d6e71a23ca",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
