{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T11:40:10.119461Z",
     "start_time": "2024-09-11T11:40:09.864179Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:40:13.450504Z",
     "start_time": "2024-09-11T11:40:10.123034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "62384f2e75fb1ccb",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>1.Data creation</b>",
   "id": "13c51492559e0fba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:40:13.481130Z",
     "start_time": "2024-09-11T11:40:13.452345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We have here a CSV file where the gunshot filenames, the number of gunshots and their starting point is stored\n",
    "gunshot_csv = pd.read_csv('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/updated_gunshot_metadata.csv')"
   ],
   "id": "8f7252c44118cf9",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:40:13.493707Z",
     "start_time": "2024-09-11T11:40:13.482028Z"
    }
   },
   "cell_type": "code",
   "source": "gunshot_csv.head()",
   "id": "287d53908443b0cd",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:40:13.504382Z",
     "start_time": "2024-09-11T11:40:13.499132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The problem with these gunshot files is that some of them are too quiet and when I place it on a music we can't really hear them. \n",
    "# So I tried to filter them and get only a set of gunshot files where the gunshots are actually loud enough to place them on a music file."
   ],
   "id": "bd109938d1664de9",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T11:42:54.059449Z",
     "start_time": "2024-09-11T11:40:13.506972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This cell was used to clean the csv data because some of the gunshot samples were too low in decibels to even hear something.\n",
    "# Load your data\n",
    "df = pd.read_csv('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/updated_gunshot_metadata.csv')\n",
    "audio_dir = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/edge-collected-gunshot-audio'\n",
    "\n",
    "def get_max_decibel_level(audio_segment):\n",
    "    \"\"\"\n",
    "    Calculate the maximum decibel level of the audio segment.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_segment (AudioSegment): The audio segment to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        max_db (float): The maximum decibel level of the audio.\n",
    "    \"\"\"\n",
    "    return audio_segment.max_dBFS\n",
    "\n",
    "def filter_gunshots_by_decibel(df, audio_dir, threshold_db=-20.0):\n",
    "    \"\"\"\n",
    "    Filter out gunshot audio files based on their maximum decibel levels and return\n",
    "    a list of files with low decibel levels for manual review.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the file paths and other metadata.\n",
    "        audio_dir (str): Directory where the audio files are stored.\n",
    "        threshold_db (float): Decibel threshold below which files will be listed for review.\n",
    "        \n",
    "    Returns:\n",
    "        filtered_df (DataFrame): DataFrame containing only the files above the decibel threshold.\n",
    "        low_db_files (list): List of file paths with low decibel levels.\n",
    "    \"\"\"\n",
    "    filtered_records = []\n",
    "    low_db_files = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_path = row['filename']\n",
    "        full_path = os.path.join(audio_dir, file_path)\n",
    "\n",
    "        # Load the audio file\n",
    "        try:\n",
    "            audio = AudioSegment.from_file(full_path)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        # Get the maximum decibel level\n",
    "        max_db = get_max_decibel_level(audio)\n",
    "        if max_db > threshold_db:\n",
    "            filtered_records.append(row)\n",
    "        else:\n",
    "            low_db_files.append(full_path)\n",
    "    # Create a new DataFrame with filtered records\n",
    "    filtered_df = pd.DataFrame(filtered_records)\n",
    "    return filtered_df, low_db_files\n",
    "\n",
    "# Define your threshold (e.g., -20 dBFS)\n",
    "threshold_db = -5.0\n",
    "\n",
    "# Filter the DataFrame based on max decibel level and get the low decibel files\n",
    "filtered_df, low_db_files = filter_gunshots_by_decibel(df, audio_dir, threshold_db=threshold_db)\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv('filtered_gunshot_metadata.csv', index=False)\n",
    "\n",
    "# Print the list of files with low decibel levels\n",
    "print(f\"Number of files with low decibel levels:{len(low_db_files)}\")"
   ],
   "id": "18fb39965d10d243",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>After we got the filtered dataset we can use those gunshots to create audio with gunshots</b>",
   "id": "be6e46e849040999"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T07:58:18.432800Z",
     "start_time": "2024-09-10T07:58:13.848761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshots_paths = pd.read_csv('./filtered_gunshot_metadata.csv')\n",
    "gunshots = gunshots_paths[['filename', 'num_gunshots', 'gunshot_location_in_seconds']].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Function to preprocess gunshot start times, converting strings to lists of floats\n",
    "def preprocess_gunshot_times(gunshot_times, include_first_gunshot_only=False):\n",
    "    # Remove multiple spaces\n",
    "    gunshot_times = re.sub(r'\\s+', ' ', gunshot_times).strip()\n",
    "\n",
    "    # Insert commas between numbers if missing\n",
    "    gunshot_times = re.sub(r'(?<=\\d)\\s(?=\\d)', ', ', gunshot_times)\n",
    "\n",
    "    # Ensure there are no trailing commas\n",
    "    gunshot_times = gunshot_times.replace(', ]', ']')\n",
    "\n",
    "    # Safely evaluate the string as a list\n",
    "    try:\n",
    "        gunshot_list = ast.literal_eval(gunshot_times)\n",
    "        if include_first_gunshot_only and isinstance(gunshot_list, list) and gunshot_list:\n",
    "            return [gunshot_list[0]]  # Return only the first gunshot time\n",
    "        return gunshot_list\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Return an empty list if the string is not a valid list\n",
    "        return []\n",
    "\n",
    "# Define the root path\n",
    "root_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/edge-collected-gunshot-audio/'\n",
    "\n",
    "# Boolean flag to control if only the first gunshot time should be included\n",
    "include_first_gunshot_only = False\n",
    "\n",
    "# Apply the function to preprocess the 'gunshot_location_in_seconds' column with the boolean flag\n",
    "gunshots['gunshot_location_in_seconds'] = gunshots['gunshot_location_in_seconds'].apply(\n",
    "    lambda x: preprocess_gunshot_times(x, include_first_gunshot_only)\n",
    ")\n",
    "\n",
    "# If include_first_gunshot_only is True, set 'num_gunshots' to 1\n",
    "if include_first_gunshot_only:\n",
    "    gunshots['num_gunshots'] = gunshots['gunshot_location_in_seconds'].apply(lambda x: len(x))\n",
    "\n",
    "# Add the label column\n",
    "gunshots['label'] = 1\n",
    "\n",
    "music_df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data_w_topics_w_features.xlsx', engine='openpyxl')\n",
    "\n",
    "music = music_df.rename(columns={'Path': 'filename'})\n",
    "music['label'] = 0\n",
    "\n",
    "music_labels = music[['label']]\n",
    "music_paths_df = music[['filename']]\n",
    "\n",
    "df = utils.generate_data_samples(music, gunshots, number_of_samples_w_gunshots=1, number_of_samples_wo_gunshots=0)"
   ],
   "id": "9027c3ecec44efe",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T07:58:18.440112Z",
     "start_time": "2024-09-10T07:58:18.434750Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "f8f2db8d90587034",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:13:51.683725Z",
     "start_time": "2024-09-10T08:13:42.055336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio = AudioSegment.from_file(df['filename'].iloc[0])\n",
    "\n",
    "# Play the audio\n",
    "play(audio)"
   ],
   "id": "602e117acbe39e86",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Model and frame sizes</b>",
   "id": "1881080d4086925d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:14:05.310928Z",
     "start_time": "2024-09-10T08:14:05.239531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model now can take any number of frames.\n",
    "\n",
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)  # Shape: (batch_size, channels, height, width)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=150)"
   ],
   "id": "3f49c38435b155c4",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:14:05.686399Z",
     "start_time": "2024-09-10T08:14:05.681541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This means that if we have 150 frames we cover: \n",
    "print(f\"{150 * utils.HOP_LENGTH / 44100} seconds\")"
   ],
   "id": "19aad216d1efb881",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:14:42.158727Z",
     "start_time": "2024-09-10T08:14:41.431762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Since we have the gunshots at 2 seconds hard, it produces all the time the same patterns. To generalize the model a bit more we shift the gunshots randomly and generate multiple samples.\n",
    "\n",
    "# Load the audio file\n",
    "def load_audio(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "# Function to plot multiple waveforms\n",
    "def plot_waveforms(waveforms, sample_rate):\n",
    "    fig, axes = plt.subplots(len(waveforms), 1, figsize=(10, 10), sharex=True)\n",
    "    if len(waveforms) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, waveform in enumerate(waveforms):\n",
    "        axes[i].plot(waveform[0].numpy())\n",
    "        axes[i].set_title(f\"Waveform {i+1}\")\n",
    "        axes[i].set_xlabel('Time (samples)')\n",
    "        axes[i].set_ylabel('Amplitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# The modified function from earlier\n",
    "def select_gunshot_segment(waveform, sample_rate, gunshot_time, frame_length, max_shift_sec=0.3):\n",
    "    random_shift = random.uniform(-max_shift_sec, max_shift_sec)\n",
    "    shifted_gunshot_time = gunshot_time + random_shift\n",
    "    start_time = max(0, shifted_gunshot_time - (frame_length / sample_rate) / 2)\n",
    "    start_sample = int(start_time * sample_rate)\n",
    "    end_sample = start_sample + int(frame_length)\n",
    "    end_sample = min(end_sample, waveform.size(1))\n",
    "    start_sample = max(0, end_sample - int(frame_length))\n",
    "\n",
    "    return waveform[:, start_sample:end_sample]\n",
    "\n",
    "# Function to play multiple audio segments\n",
    "def play_audio_segments(waveforms, sample_rate):\n",
    "    for i, waveform in enumerate(waveforms):\n",
    "        display(Audio(waveform.numpy(), rate=sample_rate))  # Convert waveform to numpy array and play\n",
    "\n",
    "# Example usage\n",
    "audio_path = df['filename'].iloc[0]\n",
    "waveform, sample_rate = load_audio(audio_path)\n",
    "\n",
    "# Parameters\n",
    "gunshot_time = 2.0\n",
    "frame_length = utils.FRAME_LENGTH\n",
    "\n",
    "print(frame_length)\n",
    "\n",
    "# Run the selection 5 times and plot + play\n",
    "waveforms = []\n",
    "for _ in range(5):\n",
    "    selected_segment = select_gunshot_segment(waveform, sample_rate, gunshot_time, frame_length)\n",
    "    waveforms.append(selected_segment)\n",
    "\n",
    "# Plot the waveforms\n",
    "plot_waveforms(waveforms, sample_rate)\n",
    "\n",
    "# Play the waveforms\n",
    "play_audio_segments(waveforms, sample_rate)"
   ],
   "id": "96eadc19cb180d11",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "4553fffa8c18c929",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
