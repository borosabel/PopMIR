{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T15:51:29.048311Z",
     "start_time": "2024-09-26T15:51:28.958897Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:51:36.382085Z",
     "start_time": "2024-09-26T15:51:29.060669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "795b35108f74e130",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T15:57:44.990914Z",
     "start_time": "2024-09-26T15:57:44.965806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)  # Shape: (batch_size, channels, height, width)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "        \n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "a04cfc6bb08b369",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:49:40.804723Z",
     "start_time": "2024-09-26T19:49:40.795780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y in zip(spectograms, sample_rates, targets):\n",
    "            X_frames, y_frames = utils.make_frames(X, y)\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        print(len(self.X))\n",
    "        tmp = th.cat(self.X)\n",
    "        print(tmp.shape)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "id": "19fef4ae7bcd6576",
   "execution_count": 65,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:49:41.943370Z",
     "start_time": "2024-09-26T19:49:41.920967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_data_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Audio/Gunshot/csv_combined/gunshot_dataset'\n",
    "\n",
    "def generate_file_dataframe(folder_path):\n",
    "    # Initialize a list to store the records\n",
    "    records = []\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.mp3') or filename.endswith('.wav') :  # Only consider mp3 files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Determine values for the third and fourth columns based on the filename\n",
    "            if 'with_gunshot' in filename:\n",
    "                timestampt = [2.0]  # Default if no number is found\n",
    "                gunshot_flag = 1\n",
    "                label = 1\n",
    "            elif 'without_gunshot' in filename:\n",
    "                gunshot_flag = 0\n",
    "                label = 0\n",
    "                timestampt = []\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Append the record to the list\n",
    "            records.append({\n",
    "                'filename': file_path,\n",
    "                'gunshot_location_in_seconds': timestampt,\n",
    "                'num_gunshots': gunshot_flag,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the records\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df = generate_file_dataframe(gunshot_data_path)"
   ],
   "id": "4894042454039124",
   "execution_count": 66,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:49:42.517631Z",
     "start_time": "2024-09-26T19:49:42.497990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GLOCK DATAFRAME MERGE\n",
    "glock_csv = pd.read_csv('glock_gunshot_metadata.csv')\n",
    "\n",
    "glock_csv = glock_csv[['filename', 'gunshot_location_in_seconds', 'num_gunshots', 'label']]\n",
    "\n",
    "include_first_gunshot_only = True\n",
    "\n",
    "# Function to preprocess gunshot start times, converting strings to lists of floats\n",
    "def preprocess_gunshot_times(gunshot_times, include_first_gunshot_only=False):\n",
    "    # Remove multiple spaces\n",
    "    gunshot_times = re.sub(r'\\s+', ' ', gunshot_times).strip()\n",
    "\n",
    "    # Insert commas between numbers if missing\n",
    "    gunshot_times = re.sub(r'(?<=\\d)\\s(?=\\d)', ', ', gunshot_times)\n",
    "\n",
    "    # Ensure there are no trailing commas\n",
    "    gunshot_times = gunshot_times.replace(', ]', ']')\n",
    "\n",
    "    # Safely evaluate the string as a list\n",
    "    try:\n",
    "        gunshot_list = ast.literal_eval(gunshot_times)\n",
    "        if include_first_gunshot_only and isinstance(gunshot_list, list) and gunshot_list:\n",
    "            return [gunshot_list[0]]  # Return only the first gunshot time\n",
    "        return gunshot_list\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Return an empty list if the string is not a valid list\n",
    "        return []\n",
    "\n",
    "# Apply the function to preprocess the 'gunshot_location_in_seconds' column with the boolean flag\n",
    "glock_csv['gunshot_location_in_seconds'] = glock_csv['gunshot_location_in_seconds'].apply(\n",
    "    lambda x: preprocess_gunshot_times(x, include_first_gunshot_only)\n",
    ")\n",
    "\n",
    "# If include_first_gunshot_only is True, set 'num_gunshots' to 1\n",
    "if include_first_gunshot_only:\n",
    "    glock_csv['num_gunshots'] = glock_csv['gunshot_location_in_seconds'].apply(lambda x: len(x))\n",
    "\n",
    "# Add the label column\n",
    "glock_csv['label'] = 1"
   ],
   "id": "7aeec34bdfd540c6",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:46:34.191343Z",
     "start_time": "2024-09-26T19:46:34.187022Z"
    }
   },
   "cell_type": "code",
   "source": "appended_df = pd.concat([df, glock_csv], ignore_index=True)",
   "id": "46e66963c367b13f",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:37:14.905045Z",
     "start_time": "2024-09-26T19:37:14.894205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = appended_df[['filename', 'num_gunshots', 'gunshot_location_in_seconds']]\n",
    "labels = appended_df[['label']]\n",
    "\n",
    "X_train_paths, X_test_paths, y_train_paths, y_test_paths = train_test_split(files, labels, test_size=0.3, random_state=42)"
   ],
   "id": "5a1b8ae4fabed8f7",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:38:07.444418Z",
     "start_time": "2024-09-26T19:37:15.468082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms_train, sample_rates_train, labels_train = utils.preprocess_audio_train(X_train_paths, max_non_gunshot_samples=1)\n",
    "spectrograms_test, sample_rates_test, labels_test = utils.preprocess_audio_train(X_test_paths, max_non_gunshot_samples=1)"
   ],
   "id": "e0d4e50ef4d0ed05",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:40:40.173379Z",
     "start_time": "2024-09-26T19:40:40.168989Z"
    }
   },
   "cell_type": "code",
   "source": "# importlib.reload(utils)",
   "id": "6e611b6e176b2bd",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:40:40.521148Z",
     "start_time": "2024-09-26T19:40:40.518749Z"
    }
   },
   "cell_type": "code",
   "source": "# spectrograms_train, sample_rates_train, labels_train = utils.preprocess_audio_train(X_train_paths.iloc[[0]], max_non_gunshot_samples=1)",
   "id": "32992d869337c07e",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:40:40.864362Z",
     "start_time": "2024-09-26T19:40:40.861330Z"
    }
   },
   "cell_type": "code",
   "source": "# len(spectrograms_train[0])",
   "id": "21a12df6bdc1bfa0",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:49:19.865779Z",
     "start_time": "2024-09-26T19:49:19.850334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 dimensions of mel-spectograms with 80 mel bands and 15 frames.\n",
    "spectrograms_train[0].shape"
   ],
   "id": "9161957c575b6f26",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T19:49:44.967895Z",
     "start_time": "2024-09-26T19:49:44.777926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = GunshotDataset(spectrograms_train, sample_rates_train, labels_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ],
   "id": "a334daba61d6a2c7",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T16:56:27.921721Z",
     "start_time": "2024-09-26T16:56:27.909890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_std = {'mean': dataset.mean, 'std': dataset.std}\n",
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump(mean_std, f)\n",
    "\n",
    "# Save using torch\n",
    "th.save({'mean': dataset.mean, 'std': dataset.std}, 'mean_std.pth')"
   ],
   "id": "e5ede55eaa2bccb4",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T16:56:28.342134Z",
     "start_time": "2024-09-26T16:56:28.339786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "id": "208d9cf0f4040d76",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T16:56:29.692218Z",
     "start_time": "2024-09-26T16:56:29.681786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_features, valid_labels, epochs=10, thresholds=None, mean=None, std=None, patience=3):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_threshold = 0.0\n",
    "    best_score = 0.0\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase with batch processing\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Normalize features\n",
    "            print(\"features shape\", features.shape)\n",
    "            print(\"mean shape\", mean.shape)\n",
    "            print(\"std shape\", std.shape)\n",
    "            features = (features - mean) / std\n",
    "\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Ensure valid_features and valid_labels are tensors without re-constructing them unnecessarily\n",
    "        valid_features = th.stack([f.clone().detach().float() for f in valid_features]).to(device)  # Stack all features into a batch tensor\n",
    "        if not isinstance(valid_labels, th.Tensor):\n",
    "            valid_labels = th.tensor(valid_labels).float().to(device)\n",
    "        else:\n",
    "            valid_labels = valid_labels.clone().detach().float().to(device)\n",
    "\n",
    "        best_epoch_threshold, current_score = evaluate_model(model, valid_features, valid_labels, thresholds, mean, std)\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_threshold = best_epoch_threshold\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best F1 score: {best_score:.4f}, model saved.\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        print(f\"TEST best_f1: {best_score} with best threshold: {best_threshold}\")\n",
    "\n",
    "        # Early stopping based on patience\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"No improvement in F1 score for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Compute and display the confusion matrix on the validation set\n",
    "    cm = compute_confusion_matrix(model, valid_features, valid_labels, best_threshold, mean, std)\n",
    "    display_confusion_matrix(cm)\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "def evaluate_model(model, features, labels, thresholds, mean, std, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluates the model to find the best threshold based on F1 score.\n",
    "    Uses batch processing for efficiency.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    # Normalize features\n",
    "    features = (features - mean) / std\n",
    "\n",
    "    with th.no_grad():\n",
    "        outputs = model(features).squeeze().cpu().numpy()\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            predictions = (outputs >= threshold).astype(float)\n",
    "            avg_f1_score = f1_score(labels.cpu().numpy(), predictions)\n",
    "\n",
    "            if avg_f1_score > best_f1_score:\n",
    "                best_f1_score = avg_f1_score\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1_score\n",
    "\n",
    "def compute_confusion_matrix(model, features, labels, threshold, mean, std):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix using batch processing.\n",
    "    \"\"\"\n",
    "    # Normalize features\n",
    "    features = (features - mean) / std\n",
    "\n",
    "    with th.no_grad():\n",
    "        outputs = model(features).squeeze().cpu().numpy()\n",
    "\n",
    "    predictions = (outputs >= threshold).astype(float)\n",
    "    all_labels = labels.cpu().numpy()\n",
    "\n",
    "    cm = confusion_matrix(all_labels, predictions)\n",
    "    return cm\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    \"\"\"\n",
    "    Displays the confusion matrix using matplotlib.\n",
    "    \"\"\"\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='magma')\n",
    "    plt.show()\n"
   ],
   "id": "c39472dcf3129a2d",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T16:56:32.935369Z",
     "start_time": "2024-09-26T16:56:30.726177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "best_threshold, best_f1 = train_model(model, optimizer, criterion, dataloader, spectrograms_test, labels_test, epochs=10, thresholds=None, mean=dataset.mean, std=dataset.std)"
   ],
   "id": "75dafb21319c1dfe",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:05.196169Z",
     "start_time": "2024-09-10T08:33:05.173592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=utils.NUM_FRAMES, sampling_rate=utils.SAMPLING_RATE, hop_length=utils.HOP_LENGTH, mean=None, std=None, step_size=None, filter_time_sec=1):\n",
    "    \"\"\"\n",
    "    Manually evaluate the model on an audio feature, returning time positions where gunshots are detected.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        feature: The feature (e.g., spectrogram) to evaluate.\n",
    "        threshold: The prediction threshold for gunshots.\n",
    "        frame_size: Number of frames to use in each evaluation.\n",
    "        sampling_rate: Audio sampling rate.\n",
    "        hop_length: Hop length in samples for each frame.\n",
    "        mean: Mean for normalization.\n",
    "        std: Standard deviation for normalization.\n",
    "        step_size: Step size for moving through frames (default: frame_size // 2).\n",
    "        filter_time_sec: Time (in seconds) to filter out close consecutive predictions.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (minutes, seconds, output) where gunshots are detected along with the model's output.\n",
    "    \"\"\"\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Normalize feature\n",
    "    feature = feature.to(device)\n",
    "    feature = (feature - mean) / std\n",
    "\n",
    "    num_frames = feature.shape[2]\n",
    "\n",
    "    # If step_size is not specified, default to half the frame size\n",
    "    if step_size is None:\n",
    "        # step_size = frame_size // 2  # Adjust step_size if necessary\n",
    "        step_size = 1\n",
    "\n",
    "    total_iterations = 0  # To count the iterations\n",
    "\n",
    "    with th.no_grad():\n",
    "        # Loop through overlapping frames with smaller step size\n",
    "        for j in range(0, num_frames - frame_size + 1, step_size):\n",
    "            total_iterations += 1\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append((output, start))  # Keep track of output and start position\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "        # Sort predictions by the time index\n",
    "        res = []\n",
    "        for output, start in predictions:\n",
    "            if output >= threshold:\n",
    "                time_in_seconds = start * hop_length / sampling_rate\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds, time_in_seconds, output))  # Add output to the result\n",
    "\n",
    "    # Filter out close consecutive detections\n",
    "    filtered_res = []\n",
    "    last_detection_time = -float('inf')  # Initialize with negative infinity to accept the first detection\n",
    "\n",
    "    for minutes, seconds, time_in_seconds, output in res:\n",
    "        if time_in_seconds - last_detection_time >= filter_time_sec:\n",
    "            # Append with output value included\n",
    "            filtered_res.append((minutes, seconds, output))\n",
    "            last_detection_time = time_in_seconds  # Update the last detected time\n",
    "\n",
    "    # Return results with raw model output for comparison\n",
    "    return filtered_res"
   ],
   "id": "403301aeefe353a",
   "execution_count": 122,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:08.063616Z",
     "start_time": "2024-09-10T08:33:05.852438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])\n",
    "# spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/I Gave You Power.mp3'])\n",
    "# spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Many Men (Wish Death) (Dirty Version).mp3'])\n",
    "# spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Heat (Official Music Video).mp3'])\n",
    "# spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/Combined/with_gunshot_4655.mp3'])"
   ],
   "id": "c6a5081b70432334",
   "execution_count": 123,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:08.999228Z",
     "start_time": "2024-09-10T08:33:08.995614Z"
    }
   },
   "cell_type": "code",
   "source": "spectrograms[0].shape",
   "id": "7195b828ffcfebcb",
   "execution_count": 124,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:09.384174Z",
     "start_time": "2024-09-10T08:33:09.378314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load mean and std from file\n",
    "with open('./mean_std.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mean = data['mean']\n",
    "    std = data['std']"
   ],
   "id": "2bc789d3d8ce420c",
   "execution_count": 125,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:16.639236Z",
     "start_time": "2024-09-10T08:33:10.188965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std, step_size=1,\n",
    "                     filter_time_sec=1.5)"
   ],
   "id": "634a029d7f2645e5",
   "execution_count": 126,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:16.645995Z",
     "start_time": "2024-09-10T08:33:16.640638Z"
    }
   },
   "cell_type": "code",
   "source": "preds, outputs = zip(*predictions)",
   "id": "986159872f71ba1e",
   "execution_count": 127,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:33:17.068257Z",
     "start_time": "2024-09-10T08:33:16.647111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.plot(outputs, preds)"
   ],
   "id": "33566bae7a50da5c",
   "execution_count": 128,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:23:52.330824Z",
     "start_time": "2024-09-10T08:23:47.485511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for spectogram in spectrograms:\n",
    "    predicted_times = manual_evaluate_test(model, spectogram, threshold=best_threshold, mean=mean, std=std, step_size=1, \n",
    "    filter_time_sec=1.5)"
   ],
   "id": "b8eef84966c9163e",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:23:52.336850Z",
     "start_time": "2024-09-10T08:23:52.333039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Current treshold is {best_threshold} \\n\")\n",
    "\n",
    "for minutes, seconds, output in predicted_times:\n",
    "    print(f\"Detected gunshot at {minutes}m {seconds:.2f}s with model output: {output:.4f}\")"
   ],
   "id": "6f24beb193cfbe1",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "ddaa388b36cc48d1",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:25:02.649885Z",
     "start_time": "2024-09-10T08:25:01.443226Z"
    }
   },
   "cell_type": "code",
   "source": "plt.plot(predicted_times, output)",
   "id": "d41827484a0bc587",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:18:49.405438Z",
     "start_time": "2024-09-10T08:18:47.050375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import torchaudio\n",
    "import torch as th\n",
    "\n",
    "def extract_sample_at_time(audio_path, start_time_sec, frame_size=utils.NUM_FRAMES, hop_length=utils.HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extracts a sample from the audio corresponding to the specified start time.\n",
    "\n",
    "    Parameters:\n",
    "        audio_path (str): Path to the audio file.\n",
    "        start_time_sec (float): The starting time in seconds to cut the sample.\n",
    "        frame_size (int): Number of frames to consider (default: 86).\n",
    "        sampling_rate (int): Sampling rate of the audio (default: 44100).\n",
    "        hop_length (int): Hop length used in preprocessing (default: 512).\n",
    "    \n",
    "    Returns:\n",
    "        waveform (Tensor): The extracted waveform.\n",
    "        sample (AudioSegment): The extracted audio segment.\n",
    "    \"\"\"\n",
    "    # Load the full audio file\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    _, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    sample_duration_sec = (frame_size - 1) * hop_length / sample_rate\n",
    "    sample_duration_ms = sample_duration_sec * 1000\n",
    "\n",
    "    # Calculate start time in milliseconds\n",
    "    start_time_ms = start_time_sec * 1000\n",
    "\n",
    "    # Extract the segment using pydub\n",
    "    sample = audio[start_time_ms:start_time_ms + sample_duration_ms]\n",
    "\n",
    "    frame_offset = int(start_time_sec * sample_rate)\n",
    "    num_frames = int(sample_duration_sec * sample_rate)\n",
    "\n",
    "    waveform, _ = torchaudio.load(audio_path, frame_offset=frame_offset, num_frames=num_frames)\n",
    "\n",
    "    return waveform, sample, sample_rate\n",
    "\n",
    "def process_and_predict(model, audio_path, start_time_sec, mean, std, threshold=best_threshold):\n",
    "    \"\"\"\n",
    "    Extracts a sample from the audio at a given time, plays it, preprocesses it,\n",
    "    and feeds it to the model to make a prediction.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        audio_path (str): Path to the audio file.\n",
    "        start_time_sec (float): The starting time in seconds to extract the sample.\n",
    "        mean (torch.Tensor): Mean used for normalization.\n",
    "        std (torch.Tensor): Standard deviation used for normalization.\n",
    "        threshold (float): Threshold to determine gunshot (default: 0.5).\n",
    "    \n",
    "    Returns:\n",
    "        prediction (str): \"Gunshot\" if the model predicts a gunshot, otherwise \"No Gunshot\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the waveform and the audio sample\n",
    "    waveform, sample, sample_rate = extract_sample_at_time(audio_path, start_time_sec)\n",
    "\n",
    "    # Play the audio sample\n",
    "    print(f\"Playing the audio sample from {start_time_sec:.2f} seconds.\")\n",
    "    play(sample)\n",
    "\n",
    "    # Ensure mean and std are on the correct device\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    waveform = waveform.to(device)\n",
    "\n",
    "    # Preprocess the waveform using your utility function\n",
    "    mel_spectrogram = utils.calculate_melbands(waveform[0], sample_rate)\n",
    "\n",
    "    # Normalize the spectrogram\n",
    "    mel_spectrogram = (mel_spectrogram - mean) / std\n",
    "\n",
    "    # Reshape and feed to model\n",
    "    with th.no_grad():\n",
    "        input_tensor = mel_spectrogram.unsqueeze(0).float()  # Add batch dimension\n",
    "        output = model(input_tensor).squeeze().item()\n",
    "\n",
    "    # Apply threshold to determine if it is a gunshot\n",
    "    if output >= threshold:\n",
    "        prediction = \"Gunshot\"\n",
    "    else:\n",
    "        prediction = \"No Gunshot\"\n",
    "\n",
    "    print(f\"Model Prediction: {prediction} with output: {output}\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "audio_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/50 Cent - Many Men (Wish Death) (Dirty Version).mp3'\n",
    "# audio_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'\n",
    "# audio_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/DMX - Ruff Ryders Anthem.mp3'\n",
    "# audio_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Audio/Gunshot/csv_combined/gunshot_dataset/with_gunshot_Just Playing (Dreams) (2005 Remaster)_glock_17_9mm(240)_346.mp3'\n",
    "model = model\n",
    "mean = mean\n",
    "std = std\n",
    "\n",
    "print(best_threshold)\n",
    "\n",
    "# Predict if there's a gunshot starting at 2 seconds\n",
    "prediction = process_and_predict(model, audio_path, start_time_sec=42.4, mean=mean, std=std)"
   ],
   "id": "8055918ecb9c5253",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T08:45:27.120257Z",
     "start_time": "2024-09-06T08:45:25.914752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Load the audio file\n",
    "def load_audio(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "# Function to plot multiple waveforms\n",
    "def plot_waveforms(waveforms, sample_rate):\n",
    "    fig, axes = plt.subplots(len(waveforms), 1, figsize=(10, 10), sharex=True)\n",
    "    if len(waveforms) == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable if there's only one waveform\n",
    "\n",
    "    for i, waveform in enumerate(waveforms):\n",
    "        axes[i].plot(waveform[0].numpy())\n",
    "        axes[i].set_title(f\"Waveform {i+1}\")\n",
    "        axes[i].set_xlabel('Time (samples)')\n",
    "        axes[i].set_ylabel('Amplitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# The modified function from earlier\n",
    "def select_gunshot_segment(waveform, sample_rate, gunshot_time, frame_length, max_shift_sec=0.8):\n",
    "    random_shift = random.uniform(-max_shift_sec, max_shift_sec)\n",
    "    shifted_gunshot_time = gunshot_time + random_shift\n",
    "    start_time = max(0, shifted_gunshot_time - (frame_length / sample_rate) / 2)\n",
    "    start_sample = int(start_time * sample_rate)\n",
    "    end_sample = start_sample + int(frame_length)\n",
    "    end_sample = min(end_sample, waveform.size(1))\n",
    "    start_sample = max(0, end_sample - int(frame_length))\n",
    "\n",
    "    return waveform[:, start_sample:end_sample]\n",
    "\n",
    "# Function to play multiple audio segments\n",
    "def play_audio_segments(waveforms, sample_rate):\n",
    "    for i, waveform in enumerate(waveforms):\n",
    "        display(Audio(waveform.numpy(), rate=sample_rate))  # Convert waveform to numpy array and play\n",
    "\n",
    "# Example usage\n",
    "audio_path = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Audio/Gunshot/csv_combined/gunshot_dataset/with_gunshot_Against All Odds_glock_17_9mm(72)_1331.mp3'\n",
    "waveform, sample_rate = load_audio(audio_path)\n",
    "\n",
    "# Parameters\n",
    "gunshot_time = 2.0  # Assume gunshot occurs at 2 seconds\n",
    "frame_length = utils.FRAME_LENGTH\n",
    "\n",
    "print(frame_length)\n",
    "\n",
    "# Run the selection 5 times and plot + play\n",
    "waveforms = []\n",
    "for _ in range(5):\n",
    "    selected_segment = select_gunshot_segment(waveform, sample_rate, gunshot_time, frame_length)\n",
    "    waveforms.append(selected_segment)\n",
    "\n",
    "# Plot the waveforms\n",
    "plot_waveforms(waveforms, sample_rate)\n",
    "\n",
    "# Play the waveforms\n",
    "play_audio_segments(waveforms, sample_rate)"
   ],
   "id": "b421d0681bbc9aad",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "82baf4c78fa97a03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T08:47:01.749708Z",
     "start_time": "2024-09-06T08:46:59.671667Z"
    }
   },
   "cell_type": "code",
   "source": "prediction = process_and_predict(model, audio_path, start_time_sec=0.7, mean=mean, std=std)",
   "id": "61fc65e370110a5d",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "cbd3f8027324032",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
