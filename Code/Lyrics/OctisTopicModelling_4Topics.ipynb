{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:00:09.476635Z",
     "start_time": "2024-05-22T16:59:52.124307Z"
    }
   },
   "source": [
    "import string\n",
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "import numpy as np\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Octis is the library which can use different implemented topic modelling techniques\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.models.CTM import CTM\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "data = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/test.json'\n",
    "\n",
    "custom_stop_words = list(STOP_WORDS)  # Existing stop words\n",
    "custom_stop_words.extend([\"ll\", \"ve\", \"'em\", \"em\", \"ho\", \"fo\", \"ah\", \"de\"])  # Tokens which doesn't really make sense to have them."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data.xlsx', engine='openpyxl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:41:16.754322Z",
     "start_time": "2024-05-22T17:41:16.591265Z"
    }
   },
   "id": "e6cd140007b55929",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# I apply a general cleanup function to the lyrics (Either way it gets preprocessed later with Octis)\n",
    "df['Lyrics'] = df['Lyrics'].apply(utils.cleanup)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:43:21.245171Z",
     "start_time": "2024-05-22T17:41:16.896458Z"
    }
   },
   "id": "359640a2272fca87",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We need to export the lyrics line-by-line into a corpus.tsv so it can be used with Octis\n",
    "with open('corpus.tsv', 'w', encoding='utf-8') as file:\n",
    "    for lyrics in df['Lyrics']:\n",
    "        if pd.notna(lyrics):  # Check if the lyrics data is not NaN\n",
    "            file.write(lyrics + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T17:41:09.765733Z"
    }
   },
   "id": "96d13729e2d1c2c7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Initialize preprocessing\n",
    "preprocessor = Preprocessing(\n",
    "    vocabulary=None,\n",
    "    max_features=None,\n",
    "    remove_punctuation=True,\n",
    "    punctuation=string.punctuation,\n",
    "    lemmatize=True,\n",
    "    stopword_list=custom_stop_words,\n",
    "    min_chars=2,\n",
    "    min_words_docs=0,\n",
    "    save_original_indexes=True,\n",
    "    min_df=0.05, # a term must appear in at least 5% of the documents; otherwise, it will be discarded.\n",
    "    max_df=0.80, # a term appearing in more than 80% of the documents will be discarded, as it might be too common and potentially less informative.\n",
    "    split=False # We don't want train, validation and test split\n",
    ")\n",
    "\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=\"/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Lyrics/octis_dataset/corpus.tsv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:52:13.133936Z",
     "start_time": "2024-05-22T17:50:11.633274Z"
    }
   },
   "id": "5c7d33fc891b610e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# I save the dataset because it exports a file called indexes.txt. It is important because during the preprocessing steps the preprocessor\n",
    "# can get rid of a few documents if they don't have enough words or maybe they are too short. (For example intro files).\n",
    "# I can load the indexes.txt file and use it as a list of indexes and apply it on the original dataframe so I don't have size mismatch.\n",
    "dataset.save('./')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:52:21.667897Z",
     "start_time": "2024-05-22T17:52:21.645628Z"
    }
   },
   "id": "1a21210dfd9b6a64",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "best_coherence = -1\n",
    "best_diversity = -1\n",
    "best_params = {}\n",
    "topic_nums = [2, 3, 4, 5, 10]\n",
    "epoch_nums = [100, 200, 300]\n",
    "\n",
    "for num_topics in topic_nums:\n",
    "    for num_epochs in epoch_nums:\n",
    "        # Initialize and train the CTM model\n",
    "        model = CTM(num_topics=num_topics, inference_type=\"combined\", num_epochs=num_epochs, use_partitions=False, bert_model=\"bert-base-nli-mean-tokens\")\n",
    "        model_output = model.train_model(dataset)\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        coherence = Coherence(texts=dataset.get_corpus(), topk=10)  # Adjust 'topk' as needed\n",
    "        coherence = coherence.score(model_output)\n",
    "\n",
    "        # Calculate Topic Diversity\n",
    "        diversity_model = TopicDiversity(topk=10)\n",
    "        diversity = diversity_model.score(model_output)\n",
    "\n",
    "        # Evaluate based on coherence\n",
    "        if coherence > best_coherence or (coherence == best_coherence and diversity > best_diversity):\n",
    "            best_coherence = coherence\n",
    "            best_diversity = diversity\n",
    "            best_params = {'num_topics': num_topics, 'num_epochs': num_epochs}\n",
    "\n",
    "        with open(f'ctm_model_{num_topics}_{num_epochs}.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "print(f\"Best Coherence: {best_coherence}\")\n",
    "print(f\"Best Diversity: {best_diversity}\")\n",
    "print(f\"Best Parameters: {best_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:01:49.964342Z",
     "start_time": "2024-05-22T17:52:49.775326Z"
    }
   },
   "id": "ce56f2fcd05453e3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import os\n",
    "\n",
    "model_directory = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Lyrics/octis_dataset/CTM_Models'\n",
    "model_files = [f for f in os.listdir(model_directory) if f.endswith('.pkl')]\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "coherence_scores = []\n",
    "labels = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    with open(os.path.join(model_directory, model_file), 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    model_output = model.train_model(dataset)\n",
    "\n",
    "    coherence = Coherence(texts=dataset.get_corpus(), topk=10)\n",
    "    coherence_score = coherence.score(model_output)\n",
    "\n",
    "    # Store results\n",
    "    coherence_scores.append(coherence_score)\n",
    "    labels.append(model_file.replace('.pkl', ''))\n",
    "\n",
    "# Combine labels and coherence_scores for sorting\n",
    "model_scores = list(zip(labels, coherence_scores))\n",
    "\n",
    "# Sort models based on coherence score\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip sorted lists\n",
    "labels_sorted, coherence_scores_sorted = zip(*model_scores_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:13:21.204883Z",
     "start_time": "2024-05-22T18:06:55.212584Z"
    }
   },
   "id": "4b57f207cf0af32b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Plotting coherence scores\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(labels_sorted, coherence_scores_sorted, label='Coherence Score', marker='o', color='blue')\n",
    "plt.title('Coherence Scores by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=90)  # Rotate labels for better readability\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('topic_coherence_by_model_type.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:16:27.084048Z",
     "start_time": "2024-05-22T18:16:26.114643Z"
    }
   },
   "id": "724690b7e90ac933",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# model = CTM(num_topics=best_params['num_topics'], inference_type=\"combined\", num_epochs=best_params['num_epochs'], use_partitions=False, bert_model=\"bert-base-nli-mean-tokens\")\n",
    "\n",
    "# Load the model instead\n",
    "with open(\"/Users/borosabel/Documents/Uni/Thesis/PopMIR/Code/Lyrics/octis_dataset/CTM_Models/ctm_model_2_300.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "    \n",
    "model_output = model.train_model(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:15.455872Z",
     "start_time": "2024-05-17T09:30:43.351317Z"
    }
   },
   "id": "c55a8ec6fea90239",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "coherence = Coherence(texts=dataset.get_corpus(), topk=10)  # Adjust 'topk' as needed\n",
    "topic_diversity = TopicDiversity(topk=10)\n",
    "coherence_score = coherence.score(model_output)\n",
    "diversity_score = topic_diversity.score(model_output)\n",
    "\n",
    "print(\"Coherence Score:\", coherence_score)\n",
    "print(\"Diversity Score:\", diversity_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:16.453159Z",
     "start_time": "2024-05-17T09:31:15.461543Z"
    }
   },
   "id": "e0d28f2f2fe6d786",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# We decide on the topic based on the maximum probability of the topic.\n",
    "dominant_topic_indices = np.argmax(model_output['topic-document-matrix'], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:26.511974Z",
     "start_time": "2024-05-17T09:31:26.508499Z"
    }
   },
   "id": "4c5c38a0953df2a9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dominant_topics = []\n",
    "for i in dominant_topic_indices:\n",
    "    dominant_topics.append(model_output['topics'][i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:27.046953Z",
     "start_time": "2024-05-17T09:31:27.040857Z"
    }
   },
   "id": "aaecf1bfb755b8cb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# We load the previously saved indexes file because in this way we can filter the documents by index. Some documents may not included in the analysis due to the preprocessing steps\n",
    "file_path = 'indexes.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    indices = [int(line.strip()) for line in file]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:28.383832Z",
     "start_time": "2024-05-17T09:31:28.376802Z"
    }
   },
   "id": "a0942d7d2e314d48",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "filtered_df = df.iloc[indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:28.929336Z",
     "start_time": "2024-05-17T09:31:28.926716Z"
    }
   },
   "id": "692afeb3e4b22722",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# This is just to make sure that in the filtered dataframe we have the same ammount of songs than in the preprocessed dataset.\n",
    "filtered_df.shape[0] == dominant_topic_indices.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:29.429746Z",
     "start_time": "2024-05-17T09:31:29.427140Z"
    }
   },
   "id": "4054c8e1b285b57b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "filtered_df['Topic Model Index'] = dominant_topic_indices\n",
    "filtered_df['Topic Model'] = dominant_topics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:30.223045Z",
     "start_time": "2024-05-17T09:31:30.217577Z"
    }
   },
   "id": "3ff8aede95940992",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:30.817130Z",
     "start_time": "2024-05-17T09:31:30.806492Z"
    }
   },
   "id": "7527e93a500d6269",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "filtered_df.to_excel('baseline_w_topics_w_entity.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T21:07:01.774373Z",
     "start_time": "2024-05-14T21:07:01.148326Z"
    }
   },
   "id": "7674beed1686da32",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "topic_coast_distribution = pd.crosstab(filtered_df['Topic Model Index'], filtered_df['Coast'])\n",
    "print(topic_coast_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:34.339128Z",
     "start_time": "2024-05-17T09:31:34.331332Z"
    }
   },
   "id": "b70a9bfa7995a321",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Normalization of the topic distribution over the entire dataset\n",
    "total_songs = topic_coast_distribution.sum().sum()\n",
    "topic_coast_distribution_normalized = topic_coast_distribution / total_songs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:35.809948Z",
     "start_time": "2024-05-17T09:31:35.807442Z"
    }
   },
   "id": "a89b3bb643b1de7b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "model_output['topics']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:36.653684Z",
     "start_time": "2024-05-17T09:31:36.649160Z"
    }
   },
   "id": "3c8a911a7f67269b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Assuming topic_coast_distribution_normalized is already defined\n",
    "colors = ['red', 'blue']\n",
    "topic_labels = ['Rhyme, Rapper Lifestyle', 'Violence, Street']\n",
    "\n",
    "# Create the bar plot\n",
    "ax = (topic_coast_distribution_normalized * 100).plot(kind='bar', figsize=(10, 6), color=colors)\n",
    "plt.title('Proportional Contribution of Each Coast to Topics (Global Normalization)')\n",
    "plt.xlabel('Dominant Topic')\n",
    "plt.ylabel('Percentage of Total Songs')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Coast')\n",
    "\n",
    "# Change the x-axis labels to the topic descriptions\n",
    "ax.set_xticklabels(topic_labels)\n",
    "\n",
    "# Adding percentage labels\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    if height > 0:  # Only add annotations for non-zero values\n",
    "        ax.annotate(f'{height:.2f}%', (x + width/2, y + height*0.5), ha='center')\n",
    "\n",
    "plt.savefig('coast_topic_contribution.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:44.224643Z",
     "start_time": "2024-05-17T09:31:43.606359Z"
    }
   },
   "id": "6b1938315188537a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e91a1939fb46e2ee",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
